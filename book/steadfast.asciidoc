= Steadfast Self-Hosting: Rapid-Rise Personal Cloud
:author: Adam Monsen
:copyright: (C)2025 {author}
:doctype: book
:docinfo:
:toc: macro
:toclevels: 2
:imagesdir: img
:front-cover-image: image:cover.png[]
:icons: font
:xrefstyle: full
:hide-uri-scheme:
// see https://pygments.org/languages/ for available languages and their short names
:source-highlighter: pygments
:!chapter-signifier:
// prevent unnecessary blocking fetch of fonts
:!webfonts:
:pdf-themesdir: pdf-theme
ifdef::shb-screenPDF[]
:pdf-theme: screen.yml
endif::[]
ifdef::shb-printPDF[]
:!front-cover-image:
:pdf-theme: print.yml
:media: prepress
endif::[]
// necessary for keyboard macro (kbd)
:experimental:
:keywords: linux, web, servers, sysadmin, computers, tech, self-hosting, FOSS
:description: Quickly learn the hows and whys of reliable self-hosted web services.
:revnumber: {build_git_tag}
:revdate: {build_date_time}
:revremark: {build_locale_lang}
// see https://docs.asciidoctor.org/asciidoc/latest/blocks/add-title/#captioned-titles
:listing-caption: Listing

ifdef::backend-html5[]
// https://github.com/asciidoctor/asciidoctor/issues/857
++++
<style>
  .imageblock > .title {
    text-align: inherit;
  }
</style>
++++
endif::backend-html5[]

include::locale/attributes-de.adoc[]

[colophon%notitle%nonfacing]
== Colophon

--
_{doctitle}_
--

--
{copyright}.
Some rights reserved.
This book is licensed under a https://creativecommons.org/licenses/by-sa/4.0/[Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) License].

image::cc-by-sa.svg[align="center"]
--

--
Das wunderschöne Titelbild wurde von meiner Tochter mit Krita gestaltet.
Mehr von ihrer großartigen Kunst findest du im Laufe des Buches.
--

--
Technical editing by https://www.wondra.codes[Lenny Wondra].
--

--
German translation by Fiona Burkart.
--

--
First published in 2024 by https://sunrisedata.io[Sunrise Data Press].
--

--
Seattle, Washington, USA.
--

ifdef::backend-epub3[]
--
EPUB ISBN: 979-8-9908615-0-3
--
endif::[]

ifdef::shb-screenPDF[]
--
PDF ISBN: 979-8-9908615-2-7
--
endif::[]

ifdef::shb-printPDF+printQuality-standard[]
--
Paperback ISBN: 979-8-9908615-1-0
--

--
Library of Congress Control Number: 2024911437
--
endif::[]

ifdef::shb-printPDF+printQuality-premium[]
--
Premium paperback ISBN: 979-8-9908615-3-4
--
endif::[]

// "big" is perhaps deprecated, see https://docs.asciidoctor.org/asciidoc/latest/text/text-span-built-in-roles/#built-in
//
// ...or maybe it is only deprecated for HTML? See https://docs.asciidoctor.org/pdf-converter/latest/roles/

--
[.text-center]
image:sunrisedata-logo.svg[alt=Sunrise Data logo,width=49,height=97,fit=line] [.big]#Sunrise Data Press#
--

toc::[]

== Vorwort

Bevor ich 2006 anfing, im Open-Source-Bereich zu arbeiten, war ich als Community-Organisator in Massachusetts tätig.
Ich kannte die Auswirkungen eines Mangels an Informationszugang oder das Fehlen des „richtigen“ Handbuchs sehr gut – beides hindert Menschen daran, mitzubestimmen, wie sie ihr Leben gestalten.
Als Community-Organisatorin brachte ich den Menschen bei, wie man Lobbyarbeit betreibt.
Unsere Organisation lud Menschen ein, gemeinsam mit Abgeordneten Gesetze zu entwerfen, die ihren Bedürfnissen gerecht wurden und ihr Leben verbesserten.
Wir zeigten ihnen, wie man Spenden sammelt, und wie sie sich selbst und ihre Nachbarschaft organisieren können.
Und dann verlagerte sich alles zunehmend ins Internet – und wichtige Diskussionen darüber, wie wir die Schwächsten schützen und die nächste Generation stärken können, begannen, über unsere Computer stattzufinden.

Man kann Fortschritt entweder beklagen oder ihn annehmen.
Ich entschied mich dafür, ihn anzunehmen. Ich wollte Menschen stärken und ihnen helfen, ein Gefühl von Kontrolle über ihre Computer- und Technologienutzung zu erlangen.
Ich begann, ganz unterschiedliche Menschen aus der Freie-Software-Bewegung kennenzulernen. Einige von ihnen interessierten sich sehr dafür, wie der Code funktioniert, und andere - wie Adam - waren vor allem daran interessiert, auf welche Weise frei zugänglicher Code Menschen helfen kann.

Adam und ich lernten uns 2009 bei ((LFNW)) (LinuxFest Northwest) kennen, einer kostenlosen Community-Konferenz in Bellingham, Washington.
Ein gemeinsamer Freund hatte mir empfohlen, bei einem Besuch in Washington anlässlich des LFNW auch einmal Seattle zu besuchen – was bedeutete, dass wir gemainsam von Seattle nach Bellingham fuhren.
Wir trafen uns alle in Seattle zum Mittagessen und machten uns dann gemeinsam auf die zweistündige Autofahrt nach Bellingham.
Auf diesen Fahrten begannen wir wirklich, über das Fehlen einer Freie-Software-Veranstaltung in Seattle zu sprechen.
Uns wurde klar, dass es in Seattle Leute brauchte, die ihre Unternehmen zur Sponsorenrolle bewegen konnten (wie Adam und Rob Smith), und jemanden, der sich um Referenten kümmern und die Veranstaltung in der Freie-Software-Community bekannt machen konnte – und so kam es, dass ich (als Bewohnerin von Massachusetts) Mitbegründerin einer jährlichen Veranstaltung in Seattle wurde.

[#image-seagl-crew]
.Die SeaGL crew. Von links nach rechts: Salt, Deb, Patch, (mit french fry), Adam, Rob. Nicht im Bild: Chris, Jesse, Bri, Lisa, and viele andere.
image::seagl-crew.jpg[align="center",scaledwidth=80%]

Die erste ((SeaGL)) fand 2013 am Seattle Central College statt und war ziemlich improvisiert.
Keine Keynotes, viele gemeinsam genutzte Mehrfachsteckdosen und ein paar Freund*innen, die hineingezogen worden waren, ohne genau zu wissen, worauf sie sich da eingelassen hatten.
Wir hatten bewusst einen Freitag gewählt, um eventuell Studierende anzusprechen, solange der Campus geöffnet war, und einen Samstag, um den zweiten Tag für diejenigen zugänglich zu machen, deren Arbeitsstellen eine Teilnahme unter der Woche nicht unterstützten.
Die Veranstaltung war – und ist bis heute – kostenlos und offen für alle.

Adam tauchte bei unserer ersten Veranstaltung mit einem kleinen Stapel „Print-on-Demand“-Hüten und -T-Shirts auf, versehen mit unserem brandneuen Logo (natürlich eine seagull (eng. Möwe).
Die Auswahl der Vorträge lief nach dem Motto: „Wenn du einen Vortrag halten willst, dann halt einen.“
Adam hielt großartige Einführungsvorträge zu Git und Hadoop, und ich sprach über politische Rahmenbedingungen und Community-Organizing.
Wir hatten es noch nicht schriftlich festgehalten, aber SeaGL war von Anfang an dazu bestimmt, eine Konferenz für Anfängerinnen und Expertinnen zu sein, für Programmierer*innen und Politikbegeisterte, und für Vorträge über das gesamte Ökosystem – seine Schwächen, sein Potenzial und die Chancen zur Zusammenarbeit mit anderen Initiativen, die Menschen stärken wollen.

Nach dieser chaotischen ersten Ausgabe wurde uns klar: SeaGL sollte für alle sein – aber ganz besonders für Menschen, die einen Einstieg in Open Source suchten, in einer vielfältigen, teuren und technologiegetriebenen Region wie Seattle.
Wir wollten, dass SeaGL eine großartige erste Tech-Konferenz für Teilnehmende wird und eine einladende Plattform für angehende Vortragende bietet.
Später weiteten wir dieses Ziel aus und bemühten uns gezielt darum, weniger bekannte Sprecher*innen zu finden und ihnen ihre erste Keynote-Möglichkeit zu bieten.
Das gesamte SeaGL-Team (einschließlich Adam, natürlich!) war und ist mit voller Leidenschaft dabei, Neulinge willkommen zu heißen und eine freundliche, sichere und neugierige Atmosphäre zu schaffen.

Adam und ich kennen uns schon seit vielen Jahren.
Ich habe seine Tochter kennengelernt, die die talentierte Illustratorin dieses Buches ist, und auch seine Frau, die klug ist und unermüdlich neugierig darauf, wie Technologie unser Leben beeinflusst.
Sogar einige der Hühner habe ich getroffen – sie sind tatsächlich blitzsauber, wenn auch leider nicht besonders schlau.
Zum Glück werden sie äußerst gut versorgt, sodass sie nicht allzu viel Grips brauchen.

Kurz gesagt: Adam ist sehr engagiert – sowohl für Freie Software als auch dafür, Menschen zu stärken.
Außerdem ist er unglaublich nett!
Wirklich einer der nettesten Menschen, die ich je getroffen habe.
Wenn dich die Vorstellung anspricht, etwas Herausforderndes mit einem geduldigen und einfühlsamen Mentor anzugehen, und du neugierig auf das Thema Self-Hosting bist, dann ist dieses Buch genau das Richtige für dich.

Self-Hosting ist schwierig.
Ich selbst habe still Mailinglisten verfolgt, die versprachen, es einfach zu machen. Ich habe Vorträge besucht, Videos geschaut und Artikel gelesen – aber wirklich einfach wurde es nie.
Manche dieser Ressourcen fingen gefühlt erst bei Kapitel 2 an, andere waren voller Kommentare, die einem das Gefühl gaben, dass jede einigermaßen intelligente Person die fehlenden Informationen schon irgendwie selbst finden müsste.
Zum Glück hat Adam alles aufgenommen, was echte Anfänger*innen brauchen, um loszulegen – und dabei trotzdem viele Wahlmöglichkeiten offengelassen.

Self-Hosting ist aber auch wichtig.
In der Technik – und in der Welt insgesamt – verändert sich vieles sehr schnell.
Was man kontrolliert und was nicht, ist ständig im Wandel.
Self-Hosting gibt dir die Möglichkeit, ein paar Dinge in deiner eigenen Hand zu behalten – deine persönlichen Daten, deine Medien und die Art, wie du mit deiner digitalen Umgebung interagierst.
Es ermöglicht dir, selbst zu entscheiden, was du brauchst, und selbst zu wählen, wie du diesen Bedarf decken willst – ohne um Erlaubnis zu fragen oder dich an ein Unternehmen zu binden, dem du als Individuum egal bist.

Du solltest dieses Buch lesen, es mit anderen teilen und vielleicht – wenn du soweit bist – etwas an die Self-Hosting-Community zurückgeben.

--
Willkommen in der Welt des Self-Hosting,
--

[.big]#Deb Nicholson#

--
Gründerin, Seattle GNU/Linux Conference +
Geschäftsführerin, Python Software Foundation
--

:sectnums:

== Einführung

(((Datensouveränität)))
Datensouveränität bedeutet, die volle Kontrolle über die eigenen Daten zu haben.
Sie verspricht Privatsphäre, Freiheit und Nachhaltigkeit.
Datensouveränität zu verwirklichen ist sowohl spannend als auch praktisch – und sie fördert ((prosoziales Verhalten)).
Self-Hosting (also das Betreiben eines eigenen Servers) ist ein hervorragender Weg zur Datensouveränität.

Dieses Buch wird dir helfen, Self-Hosting effizient zu erlernen und in der Praxis anzuwenden.
Du wirst Selbstvertrauen im Umgang mit den damit verbundenen Herausforderungen gewinnen und die Vorteile aus erster Hand erleben.
Die Fähigkeiten, die du dir aneignest, sind sowohl zu Hause, am Arbeitsplatz als auch in deiner Gemeinschaft anwendbar.

=== Willkommen

Ich freue mich sehr dass du hier bist!

Ich möchte dir dabei helfen, einen Server zum Laufen zu bringen.
Das Self-Hosting-Ökosystem ist überfüllt und oft verwirrend – deshalb habe ich eine Reihe schwieriger Entscheidungen bereits für dich getroffen, basierend auf sinnvollen und erprobten Voreinstellungen.
Ich werde dir dabei helfen, deinen eigenen Server bereitzustellen (einzurichten) und einige nützliche Webdienste darauf zu installieren.
Bring mit, was auch immer du an Sysadmin-Erfahrung hast, ein paar motivierte Nutzer*innen – und den Wunsch, dir echte Self-Hosting-Kompetenz anzueignen.

Das Internet ist oft ein unerbittlicher Kampf um Geld und Aufmerksamkeit.
Unser Verhalten wird endlos getrackt – wir sind das Produkt.
Der Smog der Überwachung erstickt unsere Freiheit und untergräbt das Vertrauen.
Wir werden:

* Uns nicht mit billigen ((Cloud))-Diensten zufriedengeben.
* Ablenkungen reduzieren.
* Unsere Aufmerksamkeit, Zeit und Freiheit wertschätzen.
* Die klare, frische Luft geringerer Überwachung atmen, indem wir selbst eine Alternative zum erschreckenden gesellschaftlichen Standard schaffen, Privatsphäre gegen Bequemlichkeit zu tauschen.
* Geld sparen, indem wir viele Dienste effizient auf eigener Hardware betreiben – mit kaum zusätzlichen Kosten.
* Gutes tun für unsere Freund*innen, Familien und sozialen Gruppen.
* Dinge tun, die mit öffentlichen Diensten nicht möglich sind, weil wir vollständigen Zugriff auf unsere Rohdaten haben.
* Uns anpassen und wachsen, wenn sich Software weiterentwickelt – und dabei unsere Daten und Metadaten mitnehmen.
* Teilen, was und wann es sinnvoll ist – mit den Menschen, denen wir vertrauen.

Dies ist das Buch, das ich mir gewünscht hätte, als ich versucht habe, meinen Kindern ein sicheres Online-Erlebnis zu ermöglichen.

Neue Self-Hosterinnen können dieses Buch als Einstieg nutzen.
Erfahrene Self-Hosterinnen können meine Entscheidungen mit ihren eigenen vergleichen.

==== Voraussetzungen

Um das Beste aus diesem Buch herauszuholen, solltest du über grundlegende Sysadmin-Erfahrung verfügen. Dazu gehört die Fähigkeit, deinen Router und dein LAN (lokales Netzwerk) zu konfigurieren, Linux auf einem Computer zu installieren (im Folgenden als dein Server bezeichnet), dich per SSH (Secure Shell) mit deinem Server zu verbinden, Textdateien zu bearbeiten und Befehle auf dem Server auszuführen sowie Dateien zwischen deinem Server und anderen Geräten zu übertragen.

Falls dir eines dieser Konzepte nicht vertraut ist, hilft dir ein kurzer Abstecher zu deiner bevorzugten Suchmaschine oder ein Besuch bei einer lokalen Nutzergruppe sicher weiter.

Ich empfehle das Hosting auf Bare Metal (greifbarer, lokal betriebener Computer-Hardware), was einige Anforderungen an den physischen Standort deines Servers mit sich bringt.
Mehr zu den Details und Anforderungen von Bare-Metal-Hosting findest du im Abschnitt <<Hardware vorbereiten>>.

Zum Schluss noch einige bewährte Vorgehensweisen, die du beim Lesen im Hinterkopf behalten solltest:

Dokumentiere alles, was du tust – selbst wenn es nur für dein zukünftiges Ich ist.
Hole dir Unterstützung und bilde andere aus, indem du deine Dokumentation nutzt, um Wissen weiterzugeben.
Bleib fokussiert, mach Pausen, sei geduldig und achte auf deinen Körper.
Bitte um Hilfe und fordere aktiv Rückmeldungen ein.
Höre auf deine Nutzer*innen, sammle Daten und passe dich entsprechend an.

=== Unterstütze den Author

Ich habe dieses Buch aus nach jahrelanger Recherche mit eigenen Reseourcen  viel Unterstützung großartiger Menschen geschrieben.
Siehe <<Danksagungen>> (gegen Ende des Buches).

Bitte https://selfhostbook.com/buy/[kaufe ein Exemplar] für dich selbst oder für jemand anderen – besonders, wenn du möchtest, dass ich in Zukunft weitere Bücher schreibe.

=== Textversion

Dieses Buch wurde am *{build_date_time}* mit `LANG` auf Einstellung `*{build_locale_lang}*` von der Quelle `{docname}{docfilesuffix}` mit Stand `{build_git_commit}`, Zweig `{build_git_branch}`, Makierung `{build_git_tag}`, mit *{build_os_release}* generiert.

=== Urheberrecht und Lizenz

_{doctitle}_ ist {copyright}.
Manche Rechte vorbehalten.

==== Vervielfältigung dieses Buches

Dieses Buch steht unter der Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) Lizenz.

image::cc-by-sa.svg[align="center"]

===== Sie dürfen

Teilen::
  das Material in jede Format oder Medium vervielfältigen und weiterverbreiten und zwar für beliebige Zwecke, sogar kommerziell.
Bearbeiten::
  das Material remixen, verändern und darauf aufbauen und zwar für beliebige Zwecke, sogar kommerziell.

_Der Lizenzgeber kann diese Freiheiten nicht widerrufen solange Sie sich an die Lizenzbedingungen halten._

//Share::

===== Unter folgenden Bedingungen...

Namensnennung::
  Sie müssen angemessene Urheber- und Rechteangaben machen, einen Link zur Lizenz beifügen und angeben, ob Änderungen vorgenommen wurden.
  Diese Angaben dürfen in jeder angemessenen Art und Weise gemacht werden, allerdings nicht so, dass der Eindruck entsteht, der Lizenzgeber unterstütze gerade Sie oder Ihre Nutzung besonders.
Weitergabe unter gleichen Bedingungen::
  Wenn Sie das Material remixen, verändern oder anderweitig direkt darauf aufbauen, dürfen Sie Ihre Beiträge nur unter derselben Lizenz wie das Original verbreiten.
Keine weiteren Einschränkungen::
  Sie dürfen keine zusätzlichen Klauseln oder technische Verfahren einsetzen, die anderen rechtlich irgendetwas untersagen, was die Lizenz erlaubt.

===== Hinweise

Sie müssen sich nicht an diese Lizenz halten hinsichtlich solcher Teile des Materials, die gemeinfrei sind, oder soweit Ihre Nutzungshandlungen durch Ausnahmen und Schranken des Urheberrechts gedeckt sind.

Es werden keine Garantien gegeben und auch keine Gewähr geleistet.
Die Lizenz verschafft Ihnen möglicherweise nicht alle Erlaubnisse, die Sie für die jeweilige Nutzung brauchen. Es können beispielsweise andere Rechte wie Persönlichkeits- und Datenschutzrechte zu beachten sein, die Ihre Nutzung des Materials entsprechend beschränken.


==== Kopiere auch den Code dieses Buches

Siehe <<Weitere Ressourcen>> für den Source Code.
Der source code umfasst zwei Originalwerke, die du kopieren, verändern und weitergeben darfst.
Zum einen das Buch selbst, inklusive des Codes zur Erstellung schön gesetzter Versionen.
Zum anderen ein Lernwerkzeug namens mario (siehe <<_mario>>).

Die Lizenz für sämtlichen originalen Source Code im Zusammenhang mit diesem Buch ist die GNU AGPL (Affero General Public License), veröffentlicht von der Free Software Foundation, entweder in Version 3 der Lizenz oder (nach deiner Wahl) jeder späteren Version.
Eine Kopie der AGPL ist in `mario/COPYING` enthalten.


=== Haftungsausschluss

Ich übernehme keine Gewährleistung und keine Garantie.
Der Kauf oder das Lesen dieses Textes stellt keine Vereinbarung über Support dar.

Obwohl bei der Erstellung dieses Buches mit größter Sorgfalt vorgegangen wurde, übernehme ich keine Verantwortung für Fehler oder Auslassungen sowie keine Haftung für Schäden, die aus der Nutzung des Codes oder der Inhalte entstehen.

Ich bin nicht beruflich mit den im Buch genannten Produkten verbunden und werde von den genannten Unternehmen nicht bezahlt.
Deren Urheberrechte, Marken und geistiges Eigentum gehören ihnen selbst.

Alle geäußerten Meinungen sind meine eigenen.

Ich beziehe mich in diesem Buch direkt auf viele Produkte und Unternehmen und teile meine konkreten, mühsam gewonnenen Erkenntnisse über ihre jeweiligen Stärken und Schwächen.
Mein Ziel ist es, aufzuklären und zu informieren.

Ich werde Abkürzungen nehmen.
Ich beabsichtige nicht, jedes Thema vollständig und erschöpfend zu behandeln.
Ich möchte, dass du schnell zum Wesentlichen kommst – und dann selbst entscheidest, ob, wann und wo du tiefer einsteigen möchtest.

Wenn du Widersprüche zu diesen Aussagen findest, gib mir bitte Bescheid.

Ich bin ein Mensch und mache Fehler.
Ich mache es dir leicht, Kontakt mit mir aufzunehmen, fehlende oder fehlerhafte Informationen zu melden – und sie bei Interesse auch selbst zu verbessern.
Bitte tu das!
Siehe <<Weitere Ressourcen>> für Kontaktinformationen und Hinweise, wie du Verbesserungen teilen kannst.

=== Schreibstil

Textformattierung:

[cols="2,3",id=style]
.Typographical conventions
|===
|Styled example |Used for

|`zpool status -t` |Inline command, filename, username, password, or variable.
Longer snippets of console text use language-specific syntax highlighting.
|kbd:[Ctrl+c] |Key(s) pressed on the keyboard.
|https://example.com |Bare (un-named) link.
https scheme is assumed and omitted.
|https://example.com[Example domain] |Named link.
Full URL appears in print version.
|`\https://cloud.example.com` |Non-working example link.
Replace `.example.com` with your actual domain name.
|<<System Design>> |Cross-reference to another section or chapter.
|===

Hinweise:

NOTE: Hilfreiche oder ergänzende Informationen.

TIP: Hier ist ein praktischer Tip!

IMPORTANT: Etwas von besonderer Bedeutung.

CAUTION: Eine vorsorgliche Warnung.

WARNING: Eine konkrete Warnung vor möglichen Problemen.

Seitenleisten:

****
Eigenständige oder ergänzende Inhalte werden visuell abgesetzt in einer Seitenleiste wie dieser dargestellt.
Seitenleisten können mit oder ohne Titel erscheinen.
****

Codeausschnitte:

.Beispiel-Codeausschnitt (🚀 server)
[source#example-code-snippet,bash]
----
echo foo | sed s/foo/bar/
----

Titel von Codeausschnitten können angeben, wo der Code ausgeführt werden soll.
Wird kein Ort genannt, wird der oder die beabsichtigten Ausführungsumgebungen im Text erklärt.
In diesem Fall weist „🚀 server“ darauf hin, dass dieser Bash-Skript-Ausschnitt auf deinem Server ausgeführt werden soll.

== Hintergrund

Du denkst vielleicht: „Das ist aber ganz schön viel Hintergrundinformation!“
Und du hast recht.

Ich gehe hier absichtlich so ausführlich auf den Hintergrund ein, weil ich beim Halten von Vorträgen über Self-Hosting etwas Wichtiges festgestellt habe:
Menschen wissen, wie man lernt und unterscheidet – aber sie wünschen sich eine sinnvolle Motivation, sich wirklich auf das Lernen einzulassen.

Ich hoffe, dass du genau das hier findest.

=== Wer bin ich?

Ich bin Vater, Tech-Unternehmer und begeisterter Verfechter von FOSS (freier und quelloffener Software).
Ich liebe es, zu erziehen, zu sorgen, zu lachen, zu singen, zuzuhören, zu programmieren, zu bauen, zu gestalten, zu debuggen, zu entwerfen, zu führen, zu managen – und noch mehr zu debuggen, zu lehren und zu schreiben.

Ich bin gut darin, Systeme und Prozesse zu verwalten und abzusichern, während ich gleichzeitig Datenschutz, Compliance und Zuverlässigkeit sicherstelle.

Am meisten stolz bin ich auf meine Familie, auf den Ausbau von https://mifos.org[Mifos], die Mitbegründung von https://seagl.org[SeaGL], den Verkauf von https://csats.com[C-SATS], und Buch geschrieben zu haben.

Ich betreibe seit Jahrzehnten meine eigenen Dienste.
Angefangen hat es mit einem Blog und einem Fotoalbum, die auf dem Rechner eines Freundes liefen.
Das Gefühl von Freiheit und Kontrolle war elektrisierend – und es unterstützte gleichzeitig meine Effektivität bei der Arbeit.
Deshalb habe ich weitergemacht und viele meiner Dienste selbst betrieben – wenn auch selten auf eigener Hardware.

Als ich eine Familie hatte, wuchsen unsere Anforderungen an Datenspeicherung und Funktionalität.
Ein einfaches Netzlaufwerk und Datei-Synchronisation reichten nicht mehr aus.
Zu Beginn der Pandemie saßen wir alle zuhause fest – und online.
Ich wurde skeptisch gegenüber Unternehmen, die aus dieser neuen Abhängigkeit Kapital schlagen wollten.
Also begann ich, mehr zu Hause selbst zu hosten – und stellte fest, wie überraschend einfach, nützlich und unterhaltsam das sein kann.

Etwa zur gleichen Zeit entschloss ich mich, mich von Google zu lösen (De-Googling).
Der Familienbedarf und mein Wunsch, Google zu meiden, passten hervorragend zusammen.
Self-Hosting war ein glücklicher Zufallstreffer.
Allein der Versuch, Google hinter sich zu lassen, war eine faszinierende und erfüllende Reise – begleitet von zahlreichen Self-Hosting-Experimenten.

=== Warum habe ich dieses Buch geschrieben?

Ich habe dieses Buch geschrieben, um ((Datensouveränität)) als prosoziales Verhalten zu fördern.
Dank Self-Hosting ist das heute einfacher denn je – und ich wollte dieses Wissen in Buchform weitergeben.

Die bisherigen Bücher zu diesem Thema bieten keine gute, schnelle und günstige Methode, um Self-Hosting auf eigener Hardware ((Bare Metal)) umzusetzen.
Ich habe eine solche Methode gefunden – und ich glaube, du wirst sie lieben.
Sie funktioniert übrigens auch in der Cloud, kostet dort aber deutlich mehr (siehe <<Server>>).

Außerdem: Lernen macht Spaß.
Ich lerne beim Schreiben.
Als ich erforschte, wie mein Handy eigentlich funktioniert, wurde mir bewusst, wie wichtig es ist, zu verstehen, wie „die Cloud“ funktioniert – denn moderne Smartphones basieren stark auf Cloud-Diensten und -Daten.
Beim Versuch, mein Handy wirklich „mein eigenes“ zu machen (also so, dass es mir hilft, mein bestes Leben zu leben), kam mir die Idee, meine Daten in meiner eigenen Cloud zu hosten.

Fast alle Techies, die ich kenne, hosten irgendetwas selbst – oft etwas, das ich noch nie gehört habe.
Es gibt immer einen neuen Self-Hosting-Dienst zum Ausprobieren, Lernen, Optimieren und Weiterempfehlen.

Ich wollte außerdem das Buch schreiben, das ich mir gewünscht hätte, als ich mit Self-Hosting anfing.

Und: Es sollte einfach ein Buch darüber geben.
Online findest du unzählige Videos, Artikel und Code-Schnipsel, die alles in diesem Buch und mehr abdecken.
Viele davon sind großartig.
Aber dieses Buch gehört dir – zum Nachschlagen, Ausprobieren und Lernen.

Und: Es gibt eine auffällige Lücke zwischen einem nützlichen Einzelrechner und nützlichen ((Cloud-Diensten)).
Cloud ist leicht zu bezahlen – aber die wahren Kosten sind verborgen: Überwachung, Abhängigkeit, Inflexibilität.

Ich kann mir gut vorstellen, dass wir in Zukunft Datengeräte für den privaten Haushalt besitzen werden, die Privatsphäre wirklich respektieren – so selbstverständlich wie heute ein Kühlschrank.
Solche Geräte wurden schon oft versucht und es wird immer wieder neue Versuche geben.
Bis sich ein solches Gerät durchsetzt, bleibt Self-Hosting – also das Einrichten eines eigenen Servers und eigener Dienste – eine hervorragende Lösung.


=== Warum dieser Titel?

==== Steadfast Self-Hosting

Ich mag das Wort _steadfast_ (_standhaft_).
Es erinnert mich an verlässliche Dinge und Menschen.

(((Datensouveränität)))
Der Schlüssel zu zuverlässigem Self-Hosting ist Datensouveränität.
Software wird sich ändern, Dienste werden sich ändern, du wirst dich ändern, und die Welt wird sich ändern.
Wenn deine Daten dir durch all diese Veränderungen zuverlässig dienen sollen, musst du die Kontrolle über sie haben.

Es macht tatsächlich einen Unterschied, eine eigene Kopie zu besitzen.
Du könntest den Zugriff auf etwas verlieren, das du vermeintlich „gekauft“ hast – weil du es in Wahrheit nur gemietet hast.
Es könnte sich sogar direkt vor deinen Augen verändern.
Mehr dazu:

* https://kotaku.com/sony-ps4-ps5-discovery-mythbusters-tv-1851066164[PlayStation To Delete A Ton Of TV Shows Users Already Paid For] by Ethan Gach
* https://defectivebydesign.org/what_is_drm[What is DRM?] by the Free Software Foundation
* https://nytimes.com/2023/04/04/arts/dahl-christie-stine-kindle-edited.html[It's Their Content, You're Just Licensing it] by Reggie Ugwu

(((source of truth)))
Das Speichern von Kopien von Daten, die jemand anderes für dich hostet, ist in Ordnung.
Self-Hosting geht einen Schritt weiter und verschafft dir weitreichende Kontrolle darüber, wie deine Daten verwendet und geteilt werden.
Du erhältst die Kontrolle über autoritative Kopien deiner Dateien – du weißt also, was die "Wahrheit" ist und kannst sie bestimmen.
Und das alles mit Zuverlässigkeit und Flexibilität zu einem vertretbaren Budget.

Self-Hosting bedeutet, Computerdienste von und für Einzelpersonen, Familien und Hobby-Anwender in SOHO-Umgebungen (Small Office / Home Office) bereitzustellen.

Vielleicht ist „Hosting für kleine Gemeinschaften“ sogar der treffendere Begriff.
Du liest auf jeden Fall das richtige Buch, wenn du Dienste für eine kleine Gemeinschaft bereitstellen möchtest.

Zum Schluss noch ein Hinweis zur Terminologie:
In der Informatik – insbesondere bei Compilern – bezeichnet „Self-Hosting“ einen besonders schönen Meilenstein: nämlich wenn eine Programmiersprache sich selbst kompilieren kann.
An meine Freunde in den angrenzenden Disziplinen:
Es tut mir leid, dass ich den Begriff „Self-Hosting“ hier so frei überlade, um „Hosting für kleine Gemeinschaften“ zu meinen.
Ihr hattet ihn zuerst – ich leihe ihn mir nur aus und hoffe, dass unsere kontextuellen Fahrbahnmarkierungen Zusammenstöße verhindern.

==== Rapid-Rise Personal Cloud

_Rapid_ ist dazu da, dich zu motivieren, sofort einzusteigen und zu lernen
_Rapid_ bedeutet nicht gleich _rücksichtslos_!
Ich setze mich entschieden für einen durchdachten und robusten Ansatz beim Self-Hosting ein.
Wenn du auf eine Herausforderung stößt, nimm dir Zeit – so lernst du am Ende schneller.
Sobald du ein Konzept verstanden hast, übe es.
Scheitere früh und oft – mit schnellen Iterationen auf dem Weg zur Perfektion.

_Rapid-rise_ steht oft auf einer Packung Backhefe – und ich liebe frisch gebackenes Brot.
Wenn dein Server also ein Laib Brot ist, dann ist dieses Buch deine Schnellhefe.

[#image-bread-server]
.Server in der Form eines Brots.
image::bread-server.png[align="center",scaledwidth=80%]

_Cloud_ bedeutet, dass es skalierbar und automatisierbar ist.
_Personal_ begrenzt diese Skalierbarkeit auf ein sinnvolles Maß für eine kleine Gruppe.“
Ein ((Bare Metal)) Server kann innerhalb seiner eigenen Hardware bis zu einem gewissen Maß skalieren
Es kann sich automatisch anpassen, indem es je nach ((Rechen-))Bedarf mehr oder weniger Leistung nutzt, und manuell, wenn man Hardware-Komponenten aufrüstet (zum Beispiel durch Hinzufügen einer weiteren Festplatte).”

Ich gebe zu, mein inneres Kind freut sich über die Mehrdeutigkeiten des Begriffs _Personal Cloud_.

=== Für wen ist dieses Buch??

Dieses Buch ist für Menschen, die freundlich zu anderen sind, mutig darin, Neues auszuprobieren, neugierig auf die Möglichkeiten des Self-Hostings und entweder unsicher, wie sie es angehen sollen, oder eifrig, ihr bestehendes Homelab (Self-Hosting-Setup) zu verbessern.

Dieses Buch ist für Menschen, die wissen wollen, wo ihre Daten leben, und in der Lage sein möchten, allerlei Magie damit zu vollbringen.
Es ist ein „von Grund auf“ oder „der harte Weg“-Ansatz und hält die Türen weit offen für viele Möglichkeiten mit einer prinzipientreuen Self-Hosting-Technik.
Manchmal berichte ich, was für mich funktioniert hat, anstatt konkret zu empfehlen, was du tun solltest.

Dieses Buch ist für Menschen, die neugierig auf FOSS sind oder diesem bereits zugeneigt sind.
Und – so viel ich auch über FOSS reden werde – ich bin hier nicht, um zu urteilen.
Ich bin hier, um zu wachsen, vor allem durch Teilen und Lernen.

Dieses Buch ist für Studierende, insbesondere technikaffine oder techniknahe Studierende, die in Clubs und Teams aktiv sind.

Dieses Buch bietet Motivation für Self-Hosting und einen exzellenten Lernprozess dafür.
Seine versionsspezifischen Inhalte werden voraussichtlich mit der Zeit veralten.
Seine Motivation und sein Lernprozess werden mit der Zeit immer relevanter.

Dieses Buch ist für diejenigen, die versuchen, mehr für andere und weniger für sich selbst zu leben; die selbstlos sind und dabei das „selbstlos sein“ genießen.
Führungskräfte, Eltern/Erziehungsberechtigte, Mitglieder einer Gemeinschaft oder einer kleinen Gruppe von Freunden.
Menschen, die Self-Hosting betreiben wollen, die auch andere lieben und neben der Systemadministration noch andere Dinge tun möchten.
Ich werde dir wertvolle Zeit für diese anderen Dinge sparen, während ich die Sysadmin-Anteile unterhaltsam gestalte.

Ähnlich wie bei „small community hosting“ wären _Small Group Cloud_ passendere Bezeichnungen als _Personal Cloud_.
_Small group_ (Kleingruppe) ist eine großartige Zielgröße für das, was du erschaffen wirst.
Ich würde mir die Mühe nicht machen, das alles nur für mich selbst zu tun.

Dieses Buch richtet sich an Menschen, die sich für Self-Hosting interessieren oder daran interessiert sind, damit zu beginnen.
Es ist darauf ausgelegt, die nützliche, sichere und schnelle Einrichtung eines einzelnen Bare-Metal-Servers mit vielen Diensten zu unterstützen.

Dieses Buch ist für Menschen, die _de-Google_, _de-iTunes_, _de-OneDrive_, _de-Dropbox_, _de-Wasauchimmer_ machen möchten.

=== Was ist dieses Buch _nicht_?

Dies ist kein umfassender Leitfaden zum Thema Self-Hosting.
Ich werde nicht versuchen, die endlosen Möglichkeiten aufzulisten, wie man Hardware, Betriebssysteme, Isolierungstechniken und Dienste kombinieren kann.
Dieses Buch richtet sich an den kleinen Maßstab.
Suchen Sie anderswo nach:

* Hochverfügbarkeit
* Enterprise-Sicherheit
* N+1-Redundanz
* Verwaltung vieler Rechner
* Clustering
* Single Sign-On
* Erweiterte Überwachung und Zentralisierung von Metriken
* Einhaltung gesetzlicher Vorschriften
* Erkennung und Abwehr von Eindringlingen/Bedrohungen
* Tiefgehende Sicherheitshärtung
* Betrieb eines eigenen Container-Registrierung
* 100 % Offline- / autarkes Self-Hosting

TEs gibt einige Themen wie diese, die ich überspringen oder nur kurz behandeln werde.
Jedes einzelne dieser Themen ist eine ganze Branche, ein weiteres Stück Hardware, eine Einstellung an deinem Heimrouter, eine potenzielle Karriere, keines oder alles davon – und auf jeden Fall eine Überlegung wert.
Du kannst und solltest dir ihrer bewusst sein.
Falls du das Gefühl hast, dass ich etwas, das für meine Methode des Self-Hostings kritisch relevant ist, komplett ausgelassen habe, lass es mich bitte wissen.

Dieses Buch richtet sich nicht an diejenigen, die bereits mit umfangreichen Ressourcen alles umgesetzt haben.
Wenn du 50.000 Dollar und unbegrenzt Zeit hast, um deinen Betonbunker-Homelab einzurichten … nun, darf ich eine Führung haben?
Ich würde das wirklich gern sehen.
Wenn du eher neugierig als sicher bist, kannst du trotzdem Spaß daran haben, aus meinen Entscheidungen zu lernen.

Ich schreibe nicht, um es hartgesottenen Software-Patent- und Lizenz-Aktivisten recht zu machen.
Diese großartigen Menschen werden meine absichtliche Verwendung des Wortes _open_ (_offen_) und das Weglassen des Wortes _libre_ (_frei_) sofort bemerken.
Ich liebe all diese Begriffe, ich stimme zu, dass Worte wichtig sind, und ich stehe auf der Seite der Inklusion – auch wenn das Idealismus kosten kann (wobei ich hoffe, dass diese Konzepte sich nicht ausschließen).
Ich danke den Aktivisten dafür, dass sie geholfen haben, die Nadel in Richtung Freiheit zu bewegen – zu unserem aller Nutzen.

Dieses Buch ist kein Manifest für immer und ausschließlich Self-Hosting.
Es ist vollkommen in Ordnung, einige Dienste selbst zu hosten und für andere zu bezahlen.
Du wirst deine eigene Checkliste entwickeln, was du wann selbst hosten möchtest.
Meine fokussiert darauf, mir und meiner Familie eine nützliche, verlässliche und zukunftssichere Cloud bereitzustellen.

Dieses Buch ist nicht der schnellste Weg, um Webdienste auszuprobieren.
Für viele Projekte findest du meist Demo-Instanzen im Netz.
Es gibt Cloud-Anbieter, die einen Dienst für dich betreiben und deine Daten hosten.

Siehe auch: <<Alternativen zu mario>>.

=== Wie Buch schreiben?

Wieso sprichst du wie ein Höhlenmensch?

(((Vim)))
Ich habe das Buch ursprünglich in Markdown-Klartext in meinem zuverlässigen Texteditor geschrieben, https://www.vim.org[Vim].
(((Pandoc)))
Ich habe großzügige Mengen an https://pandoc.org[Pandoc], Zeit, and Liebe angewandt.
Pandoc ist ein fantastisches FOSS-Tool, das es mir ermöglichte, diese einzelne Klartextdatei mit gut lesbarem Markdown Satzbau zu verwenden, um mehrere unterschiedliche, ansprechende Outputs zu erzeugen.
Beim Überarbeiten bin ich auf das Build-System von https://github.com/progit/progit2[Pro Git 2] gestoßen. (Danke an Scott und Ben!).
Kurz gesagt habe ich das Buch auf https://asciidoc.org[AsciiDoc] umgestellt und meinen Satzcode auf https://asciidoctor.org[Asciidoctor] portiert.
Das vereinfachte den Bucherstellungsprozess und ermöglichte mir mehr und bessere Output-Formate.

TIP: Schau dir den Quellcode an – du bist herzlich eingeladen, ihn zu bearbeiten und anzupassen.
Siehe <<Weitere Ressourcen>>.

Ich habe versucht, so viel wie möglich auf Standard-FOSS-Software zurückzugreifen und nur minimal anzupassen.
Das hat mir geholfen, mich auf den Inhalt zu konzentrieren und das Buch einfach genug zu halten, um es selbst zu veröffentlichen.

==== Wann Buch schreiben?

Immer noch mit dem Höhlenmenschen.
Reicht jetzt aber.
Ich habe dieses Buch 2023 geschrieben.
Und hör zu, selbst wir gesegneten Höhlenbewohner sollten dem Selbst-Hosting eine Chance geben.
Wir schaffen das!

==== Wo?

Seattle.

==== Hey.

Zugegeben, die letzten paar Abschnitte existieren nur, damit ich alle https://en.wikipedia.org/wiki/Five_Ws[5 Ws] (wer, was, wann, wo, warum) abdecken und das ‚Höhlenmenschen‘-Gimmick einbauen kann.

=== Eine Anmerkung zu FOSS

(((FOSS, author's bias towards)))

Ich bevorzuge FOSS gegenüber nicht-FOSS.
Das kann ein polarisierendes Thema sein.
Allein schon der Gebrauch des Begriffs FOSS statt anderer Varianten kann kontrovers sein.
Aber das alles sind nur Ablenkungen.
Gerade heute brauchen wir Kompromissbereitschaft, Geduld und Freundlichkeit.
Neugier statt Gewissheit.

Hier ist mein Versprechen an dich, lieber Leserin:

Ich werde versuchen, nicht zu sehr zu predigen.

Ich werde _praktische_ Lösungen _idealistischen_ vorziehen.
Manchmal werde ich das nicht schaffen – besonders wenn es um FOSS geht.
Am deutlichsten zeigt sich das darin, dass ich in diesem Buch nicht-FOSS-Alternativen kaum erwähne.

Ich kenne die Spannung zwischen praktischen und idealistischen Lösungen, und ich glaube, dass diese Spannung etwas Gutes ist – weil sie uns dazu bringt, kritisch zu überlegen, welche ((Cloud))-Dienste wir nutzen sollten, und nicht nur, welche wir nutzen können.
Das ist eine kurze Überlegung wert.

Unsere Daten sind wichtig, und unsere persönlichen Entscheidungen ebenso.
Ihre Auswirkungen betreffen auch die Gruppen, zu denen wir gehören – ebenso wie die Chance auf Verbesserung.

Ich glaube, dass selbstgehostetes ((FOSS)) machbar ist und viele praktische Vorteile gegenüber nicht-FOSS bietet.

Halte durch und gib mir Rückmeldung.
Du wirst deinen eigenen Mittelweg zwischen Idealismus und Pragmatismus finden, und ich bin gespannt, wo du am Ende landest.

== Deine Reise

Die stetigen Fortschritte in Hard- und Software machen Self-Hosting heute einfacher und günstiger denn je.
Und in einem entscheidenden Punkt deutlich komplexer: Für Einsteiger gibt es eine überwältigende Anzahl an Entscheidungen zu treffen.

Halte durch.
Ich helfe dir, die Auswahl einzugrenzen, indem ich dir gezielte und praxisnahe Empfehlungen gebe.

Mach dir nicht zu viele Sorgen über einzelne Entscheidungen.
Deine persönliche Cloud ist formbar.
Tausche nach Belieben Komponenten aus.
Wenn du dich mal falsch entscheidest, triff einfach eine neue Entscheidung – idealerweise basierend auf Metriken und tatsächlichen Nutzerbedürfnissen.

Du bist keine Versagerin, wenn du nicht gleich beim ersten Mal alles richtig machst.

Es ist völlig in Ordnung, langsam von dem umzusteigen, was du derzeit nutzt.
Du musst nicht alles auf einmal umkrempeln.

Es ist auch völlig in Ordnung, gar nicht umzusteigen und dieses Buch nur zur persönlichen Weiterbildung und zum Experimentieren zu nutzen.

Und es ist okay, wenn du nicht perfekt nach deinen oder den Idealen anderer lebst.
Halte an deinen Werten fest, während du sie gleichzeitig hinterfragst und weiterentwickelst.
Genieße deine Reise.

=== Warum du deine Software selbst hosten solltest

Frag dich ruhig noch einmal – wie man es tun sollte – warum zur Hölle sollte überhaupt jemand Software-Dienste selbst hosten?
Es gibt so viele gute Gründe!

* Flexibilität
** nur die Dienste ausführen, die du und deine Nutzer*innen wollen
** mehrere Dienste nutzen, die denselben Datenspeicher verwenden
** automatisiere, was du willst, wann du willst
** unbegrenztes Teilen
** unbegrenztes Streaming
** unbegrenzte Auswahlmöglichkeiten
* Spaß!
** lernen und wachsen
** Self-Hosting ist eine machbare Herausforderung
** passende Rätsel lösen, während du lernst und dich verbesserst
** Teil der florierenden Self-Hosting-Community sein
* Zukunftssicher sein
** deine Nutzer*innen von den unvorhersehbaren Änderungen proprietärer Produktpreise, Serviceangebote und UI/UX abschirmen
** deine hart erarbeiteten Daten mit Freunden und Familie teilen – für immer
** problemlos auf etwas anderes migrieren, wenn nötig (zum Beispiel, wenn ein neuer/besserer Fotoserver verfügbar wird)
** es sind wirklich die Daten, die geschützt werden müssen; die Frontends zu diesen Daten (Dateiviewer, Editoren etc.) werden sich ändern, wenn du es entscheidest
* Computing demokratisieren
** selbstgehostete Software (insbesondere FOSS) ermöglicht Daten- und Rechenautonomie
* Strom sparen
** der Energieverbrauch im Cloud-Backend pro Gerät sinkt drastisch bei wenigen Nutzern
** je mehr Nutzer, desto mehr Stromersparnis
** siehe verlinkte Artikel in <<Server>>
* Geld sparen
** selbstgehostete Hardware ist in der Regel günstiger als die Cloud (also gemietete Dienste)
** Einsparungen steigen, wenn der Speicherbedarf deiner Nutzer*innen in den Terabyte-Bereich geht
** spare mehr mit jedem weiteren Dienst, den du betreibst
** unerwartete Kosten bei Public-Cloud-Anbietern vermeiden
*** Egress-Gebühren machen es teuer, deine Daten herunterzuladen und umzuziehen
*** vergisst man, eine VM (virtuelle Maschine) zu stoppen, kann es schnell teuer werden
*** du könntest übermäßig viel Zeit und Geld damit verbringen, dich durch das verwirrende Service-Menü der Public Cloud zu kämpfen
** unerwartete Änderungen bei Public-Cloud-Anbietern vermeiden
*** Änderungen bei Lizenzgebühren
*** Änderungen bei Nutzungsgebühren
*** Änderungen bei Supportkosten
*** Änderungen im Serviceangebot
** nahezu keine zusätzlichen Kosten für weitere Nutzer und Dienste
* Geschwindigkeit / Zeit sparen
** ein lokaler Server kann deutlich bessere Reaktionszeiten haben, vorausgesetzt, die Hardware ist angemessen und die Dienste gut konfiguriert
** lokale Daten ("data locality") bedeuten, dass du keine Rundreisen zu Rechenzentren anderer machen musst, um zu experimentieren
** gemeinsamer Speicher erlaubt es dir, deine Daten über mehrere Dienste bereitzustellen, mit sinnvoll definiertem Lese-/Schreibzugriff
* Vendor Lock-in vermeiden
** du kannst Softwarefunktionen nutzen, die Public-Cloud-Anbieter nicht anbieten oder die es dort noch nicht gibt, da du vollständigen Zugriff auf deine Rohdaten hast
** wenn du etwas mit DRM kaufst, besitzt du es nicht wirklich
** gibt es eine Integration, auf die du dich verlässt? Manchmal funktioniert ein Dienst nicht mehr mit einem anderen. Das passiert bei FOSS seltener, weil jeder ein Projekt einfach forken (kopieren, ändern und teilen) kann.
* Privatsphäre
** den abschreckenden Effekt der Massenüberwachung vermeiden
** mit einer persönlichen Cloud kannst du GPS-Breitengrad und -Längengrad sicher in deinen Fotometadaten behalten
** sobald du deine Standortdaten speicherst, kannst du kreative Dinge damit tun
** wenn du deine Position und dein Verhalten nicht ständig mit Google teilen musst, warum tust du es?
** entferne dich aus der Gleichung der Nutzeranalyse – wenn du ein Video über einen fremden Dienst streamst, wissen sie und analysieren jedes Mal, wenn du (oder deine Kinder) ein Video, das du "besitzt", (erneut) ansiehst, zurückspulst, vorspulst, pausierst... aber müssen sie das wissen? warum?
* Neue Möglichkeiten erschließen
** beliebige Workflows auf hochgeladene Dateien anwenden
** vertrauenswürdige, offline-fähige generative KI-Modelle einsetzen
** Funktionen genießen, die es in öffentlichen Diensten nicht gibt

=== Warum du deine Software nicht selbst hosten solltest

Self-Hosting ist komplexer und zeitaufwendiger als das Bezahlen für die gleiche Funktionalität – besonders am Anfang.
Es erfordert Disziplin und Geduld, wie das Erlernen eines neuen Instruments (aber dieses Instrument spielt irgendwann von selbst!).

Wenn etwas kaputtgeht, bist du die Person, die es repariert.
Manchmal bekommst du eine hilfreiche Fehlermeldung, manchmal findest du im Web eine schnelle Lösung.
Manchmal bekommst du keine – und kannst auch keine finden.

CAUTION: Wenn dir Fehlersuche und Debugging keinen Spaß machen, ist Self-Hosting vielleicht nichts für dich.

Wenn du nicht sorgfältig mit ((Backups)) und Sicherheit umgehst, riskierst du Zeit, Energie und das Vertrauen von Menschen, die dir wichtig sind.

(((HVAC)))
Self-Hosting vor Ort bringt zusätzliche physische Überlegungen mit sich.
Du musst für ausreichende Stromversorgung, Konnektivität, HVAC (Heizung, Lüftung und Klimatisierung) und Sicherheit sorgen.
Stell deinen Server einfach nicht draußen ab.

== Praktische Beispiele

Ich verwende täglich viele verschiedene Softwaretools.
Ich muss etwas nachschlagen, eine Fahrt organisieren, Essen kaufen und so weiter.
Viel von dieser Software ist leider ziemlich nervig!
Sie scheint immer mehr von meiner Zeit, Aufmerksamkeit und meinem Geld zu wollen – dabei will ich doch nur das praktische Ergebnis erreichen, bei dem sie mir angeblich helfen soll.
Deshalb vertraue ich ihr immer weniger und überlege ständig, wie ich sie durch etwas ersetzen kann, das ich lieber mag und dem ich mehr vertraue.

Hier sind ein paar Beispiele, bei denen ich einen öffentlichen Dienst durch eine selbstgehostete Lösung verbessert habe – gefolgt von einigen Überraschungen, auf die ich dabei gestoßen bin.

=== Criminal chickens

Meine Familie hat ein selbstgebautes Sicherheitssystem für unsere Hühner, und die Videos sind mir wichtig.
Früher habe ich sie einfach auf YouTube hochgeladen, weil hey, es ist kostenlos und es „funktioniert einfach“, oder?

Außer wenn es das nicht tut.
YouTube fand manchmal, dass meine Hühner Spam und/oder Betrug seien.

[#image-YT-censor]
.Screenshot einer E-Mail vom YouTube-Content-Team, welches mein Video von der Hühnerstall-Kamera entfernt hat.
image::YT-censor.png[align="center",scaledwidth=80%]

Nur fürs Protokoll: Unsere Hühner sind _blitzsauber_.

[#image-squeaky-clean-chicken]
.Eine absolut rechtschaffene, fleißige, gesetzestreue Henne.
image::squeaky-clean-chicken.png[align="center",scaledwidth=50%]

Als ich meine persönliche Cloud eingerichtet hatte, fühlte ich Freiheit und Leichtigkeit beim Posten und Hosten dieser Videos.
Ich musste keine YouTube-Formulare mehr ausfüllen, nur um meine Hühner im Blick behalten zu können.
Ich kann deren Prüfung und die fälschliche Behauptung eines Richtlinienverstoßes nun getrost ignorieren.

[#image-YT-audit]
.Screenshot einer YouTube-Rechtsprüfung für meinen alten API-Client.
image::YT-audit.png[align="center",scaledwidth=80%]

Ich muss auch nicht mehr mit der YouTube-API (Application Programming Interface) arbeiten, einschließlich der Registrierung eines API-Clients und der Durchführung regelmäßiger Prüfungen.
Nachdem ich Nextcloud eingerichtet hatte, habe ich meinen YouTube-API-Client zum Hochladen von Videos gelöscht, meinen Code bereinigt und die Wartung vereinfacht.
Es stellt sich heraus, dass die Nextcloud Talk API sowieso einfacher ist, um Fotos und Videos von meinem Hühnerstall zu posten.

Mit meiner eigenen Cloud kann ich auch Quoten und Geschwindigkeitsbegrenzungen nach Belieben anpassen.
Volle Fahrt voraus!

=== Fotosuche nach Standort

Hier ist noch ein Beispiel, das für eine persönliche Cloud spricht.
Dieses hat funktioniert, weil ich es gewohnt bin, Standort-Metadaten in meinen selbstgehosteten Fotos zu speichern.

Vor einiger Zeit wollte ich bestimmte Fotos aus einem Haufen von Tausenden finden, die mehrere Terabyte Speicherplatz belegten.
Ich wusste, wo ich war, als ich die Fotos gemacht habe (auf etwa 10 Meilen genau), aber ich konnte mich nicht erinnern, wann sie aufgenommen wurden.

Meine Fotos sind einfach eine Sammlung von JPEG-Dateien.
Ich habe sie mit einem kleinen Python-Programm untersucht, das ich selbst geschrieben habe.
Ich suchte nach allen Fotos, die im Umkreis von 10 Meilen um den Punkt aufgenommen wurden, den ich kannte.
Der Schlüssel war, direkt und schnell auf die Daten zugreifen zu können.

Das ist nur ein (wahrscheinlich bald veraltetes) Beispiel.
Wenn du das hier liest, kannst du deine Fotos vielleicht schon mit einem Satz wie „Zeig mir alle Fotos, die im Umkreis von 10 Meilen um Mexiko-Stadt aufgenommen wurden“ abfragen – und es funktioniert einfach.

Dann kannst du dich der Rettung der Welt widmen.
Stell nur sicher, dass du deine Daten hast!

=== Überraschungen

Falls du dich entscheidest, weiterzumachen: gute Reise, Reisender.
Das hier macht wirklich Spaß.

Du wirst vielleicht überrascht sein, wie schnell und einfach manche Dinge beim Self-Hosting funktionieren.
Ich würde zu gern erfahren, wie es bei dir läuft.

Du wirst vielleicht aber auch überrascht sein, wie zeitaufwendig und schwierig manche Dinge sein können.
Vielleicht hängst du an der Hardware fest (und deren Stromversorgung, Verkabelung, Kühlung, Ausfällen).
Vielleicht am Netzwerk.
Vielleicht am „Change Management“ (deine Nutzerinnen davon zu überzeugen, Nextcloud statt Dropbox zu verwenden).

Hier sind einige Dinge, die mich überrascht haben – im Positiven wie im Negativen.

==== Gute Überraschungen

===== Hardware war gar nicht so schwierig.

Mit Hilfe eines Freundes (danke, Rob!) habe ich einen zuverlässigen und günstigen, generalüberholten Server gekauft.
Ich dachte, ich müsste an Kabeln, Karten und CMOS-Batterien herumbasteln.
Aber nein!
Ich habe das Gehäuse geöffnet, um einen Blick ins Innere zu werfen.
Ich konnte bestätigen: ganz normale Server-Innereien – oder zumindest nah genug dran.
Die CPUs und RAM-Riegel waren wie angekündigt vorhanden.

Ich habe ihn eingesteckt – und er hat funktioniert.

[#image-inside-chassis]
.Blick ins Innere des Servers mit zwei leeren PCI-E-Steckplätzen.
image::inside-chassis.jpg[align="center",scaledwidth=80%]

===== Containers == happy

(((Docker)))
Ich war angenehm überrascht von ((Container))s (erklärt in <<Contained services>>), insbesondere nach meinen gemischten früheren Erfahrungen mit VMs.
VMs sind anfangs einfach, weil sie sich wie echte Hardware verhalten.
Linux in eine VM zu installieren ist genauso einfach wie auf ((Bare Metal)) (manchmal sogar einfacher).
Dann kann man einen oder mehrere Dienste in der VM einrichten.
Der eigentliche Haken liegt in der Wartung:
Das Pflegen einer VM kann genauso aufwendig sein wie die Wartung eines Bare-Metal-Servers.

Container verfolgen einen anderen Ansatz und simulieren deutlich weniger von einem Bare-Metal-Server.
Sie sind im Vergleich zu VMs schneller und ressourcenschonender, was eine höhere, konfliktfreie Dichte von Diensten ermöglicht.
Das heißt: Du kannst mehr Dienste pro Server betreiben, ohne dass sie sich gegenseitig stören (z. B. weil sie unterschiedliche Versionen von PHP benötigen).
Ein Container enthält in der Regel genau einen Dienst.

(((Isolation)))
Die Isolierung von Containern ist im Vergleich zu VMs begrenzt.
Zum Beispiel wird der Kernel (der Teil des Betriebssystems, der direkt mit der zugrunde liegenden Hardware kommuniziert) gemeinsam genutzt.
Diese begrenzte Isolierung hält jedoch die Ressourcen- und Wartungskosten bei containerbasierter Isolierung deutlich niedriger als bei VMs.

Container eignen sich hervorragend für eine konsistente und stabile persönliche Cloud.
Sie lassen sich leicht deklarieren (im Code), bauen, bereitstellen, testen und reproduzieren.
Container können auch zusammen mit VMs verwendet werden: Du könntest zum Beispiel eine VM als Server nutzen, anstelle von Bare Metal.

Ich habe mich für Docker zur Verwaltung von Containern entschieden, weil es weit verbreitet ist und ich Erfahrung damit habe.
Dein Server wird dabei auch als Host bezeichnet, da er die Docker-Container hostet.

Ein Nachteil von Docker ist, dass in Beispielcode und öffentlichen Images oft Root-Zugriff vorausgesetzt wird.
Das Ausführen als `root` vereinfacht Container zwar, macht sie aber auch unsicherer.

===== Papierlos mit OCR

Eine weitere fortschrittliche Entwicklung, die ein Lächeln wert ist, ist kostenlose OCR (optocal character recognition/ optische Zeichenerkennung).
Ich versuche immer wieder, „papierlos zu werden“, indem ich all meine Papierdokumente einscanne.
Nach dem Scannen bleibe ich – wenig überraschend – mit einem Haufen PDF-Dateien voller Bilder zurück.
(((Paperless-ngx)))
Diese lassen sich ganz einfach mit Tools wie https://docs.paperless-ngx.com/[Paperless-ngx] und https://apps.nextcloud.com/apps/fulltextsearch[Nextcloud Full text search]  per OCR verarbeiten und verwalten.

===== Jellyfin funktioniert gut

((Jellyfin)) ist ein persönlicher Streaming-Medienserver.
Ich war begeistert zu sehen, wie Jellyfin sich als ausgezeichnete und vollständige FOSS-Alternative zu ((Plex)) herausgestellt hat.

==== Schlechte Überraschungen

===== Traefik-Lernkurve

Der ((Traefik))-Reverse-Proxy war überraschend herausfordernd einzurichten, da meine Netzwerkgrundlagen etwas eingerostet waren.
Ich habe ihn nun zuverlässig zum Laufen gebracht, muss aber mein grundlegendes Netzwerkwissen weiterhin verbessern.
Siehe <<Reverse Proxy>> für mehr Informationen über Traefik.

===== Nextcloud Bugs

(((Nextcloud, surprises with)))
Ich war frustriert über einige Probleme in Nextcloud.
Diese fühlten sich besonders dringend an, da ich stark darauf angewiesen bin.

Der Community-Support ist mal gut, mal weniger gut.
Nextcloud scheint außerhalb der USA populärer zu sein.

Nicht alle Nextcloud-Apps sind schon ausgereift.
Mehr unter <<Personalisierung>>.

===== Jitsi and Ports

((Jitsi)) ist eine selbstgehostete FOSS-Videokonferenzplattform.
Ich habe aufgegeben, Jitsi in Docker zum Laufen zu bringen.
Ich erinnere mich, dass viele offene Ports oder Portbereiche ein Problem waren.
Dieser Dienst könnte leichter in einer virtuellen Maschine selbst gehostet werden.

Es gibt auch eine Umgehungslösung, bei der Portbereiche bestimmten IP-Adressen zugewiesen werden, aber das geht über den Umfang dieses Buches hinaus.
Ich werde es irgendwann nochmal versuchen, weil https://jitsi.org/blog/authentication-on-meet-jit-si/[logging in is now required when using the free 8x8-hosted Jitsi service].

==== Nimm sie alle auf

Wenn es um Überraschungen geht, versuche die schlechten zu verkraften, wenn sie deine Nutzer betreffen.
Im Idealfall _bevor_ sie deine Nutzer betreffen, durch Recherche, Planung und Tests, die du wahrscheinlich schon machst.

(((dogfooding)))
Nutze selbst, was du selbst hostest.

Gib dein Bestes, um alles attraktiv und nützlich zu gestalten, und warte dann ab.
Sei geduldig.
Versuche niemals, Menschen zu zwingen, das zu nutzen, was du selbst hostest.

Ich hoffe, dieses Buch inspiriert dich mit vielen positiven Überraschungen und hilft dir und deinen Nutzern, viele negative zu vermeiden.

== Planung

Wir werden jetzt kurz die wichtigsten Punkte eines Selbsthosting-Plans durchgehen.
Ich liebe diesen Teil!
Ich freue mich auf das, was kommt, und ich weiß, dass ein solider Plan eine Vision Wirklichkeit werden lässt.

Mach _deinen_ Plan.
Pflege und verbessere deinen Plan gemeinsam mit deinem Server.
Teile den Plan mit anderen Administrator*innen.

Ja, anderen Administrator*innen.
Du brauchst jemanden, der dich vertreten kann, wenn du nicht verfügbar bist, oder eine glasklare Erwartung, dass der Server mit dir stirbt.

=== Budget

Berücksichtige die Zeit und die Kosten des Selbsthostings – für dich selbst _und deine Nutzer*innen_.
Wie viel hast du zur Verfügung und wie viel möchtest du ausgeben? Schreib eine Zahl auf und halte dich daran.

=== Ressourcen

Skizziere deine Gedanken zu den Ressourcen, die du benötigen wirst.
Einige Ideen:

Rechenleistung und Speicher::
CPU und RAM sind die grundlegenden Ressourcen, die für die Berechnung notwendig sind.
Siehe <<Map services to resources>> für Ideen, wie du Anforderungen basierend auf den Diensten, die du hosten wirst, abschätzen kannst.
GPU-Arbeitslasten werden in diesem Buch nicht behandelt, obwohl <<_whats_next>> und <<Exercises>> einige Dinge ansprechen, die du selbst ausprobieren kannst.

Datenspeicher::
Schätze, wie viel Speicherplatz du benötigen wirst.
Mit jedem Sprung in der Einheit (zum Beispiel von GB (Gigabyte) zu TB (Terabyte)) steigt die Komplexität und die Kosten deutlich an.
Dieses Buch ist für Datenspeicher bis etwa 10 TB geeignet.
Siehe <<Hard drives>> für Tipps, wie du beim Speicher durch Self-Hosting Geld sparen kannst.

Strom::
Überprüfe deine Stromrechnung auf die Kosten pro kWh und mache einige Berechnungen.
Siehe <<Server>> für ein Beispiel, wie viel Strom ein leistungsfähiger Server verbraucht.

Support::
Wer hilft dir, wenn du mal nicht weiterkommst?
<<Support>> bietet einige Ideen.

Physischer Standort::
Wo soll der Server stehen?
Musst du neue Leitungen für Strom oder Netzwerk verlegen?
<<Networking>> beschreibt meine Heiminstallation.

=== Zeitlicher Ablauf

Skizziere grob wichtige Termine, damit du und deine Nutzer vorausplanen können.
Zum Beispiel:

28.{nbsp}April::
  Brainstorming, Planung.
30.{nbsp}April::
  Hardware bestellen.
3.{nbsp}Mai::
  Ethernet-Kabel vom Router in die Garage verlegen.
5.{nbsp}Mai::
  Server einrichten: Festplatten einbauen, einschalten, Betriebssystem installieren, Dienste starten.
9.{nbsp}Juni::
  Ergebnis im Vergleich zu den ursprünglichen Zielen überprüfen.

Lade andere ein, mitzumachen, idealerweise schon zu Beginn beim Brainstorming und der Planung.
Das ist eine großartige Gelegenheit, weitere Personen einzubeziehen, die bei der Betreuung des Servers helfen können.

=== Umstellung

(((change management)))
Ihre Benutzer haben ihre Daten bereits an einem anderen Ort.
Überlegen Sie, wie Sie ihnen helfen können, ihre Daten auf den Server zu migrieren.

Der Schlüssel dazu ist ausgezeichnete Kommunikation.
Nehmen Sie dies in Ihren Plan auf und sorgen Sie für Zustimmung, da die Migrationskosten bei jeder Umstellung eine Realität sind.

TIP: Um mehr darüber zu erfahren, wie man Benutzer sanft zwischen Systemen überführt, beschäftigen Sie sich mit dem Thema _Change Management_.

=== Sysadmin Mindset

(((sysadmin, mindset of a Steadfast)))
Der Server existiert für die Nutzer.
Es ist wichtig, die richtige Einstellung zu haben, um eine hervorragende Nutzererfahrung bieten zu können.

Stelle sicher, dass deine selbstgehosteten Dienste gut für deine Nutzer funktionieren.
Bitte sie regelmäßig um Feedback und nimm es ernst.
Unterscheide sorgfältig zwischen ihren _Wünschen_ und ihren _Bedürfnissen_.

Übersetze das Wort „Nutzer“ je nach Kontext passend.
Vielleicht: „die dir am meisten am Herzen liegen, die du über alle anderen hinweg am meisten schätzt, diejenigen, die dir Sinn und Zweck geben.“
Ja, das ist etwas übertrieben.
Du verstehst den Punkt: Wir müssen aufmerksam sein, was die Nutzer erleben, sonst wird es für alle frustrierend.

Ideal ist es, wenn du deine Nutzer bereits im echten Leben kennst.
Bleibe auch im echten Leben mit ihnen in Verbindung, um sie online besser unterstützen zu können.

== System Design

Tauchen wir ein in die Gestaltung eines _Steadfast_ Systems.

=== Dienst-Stack

Ein _Steadfast_ System lässt sich gut als vereinfachter Stapel farbiger Kästchen darstellen.
Die vertikale Anordnung dieses Stacks richtet sich danach, wo und wie häufig eine Systemadministratorin wahrscheinlich auf dieser Ebene agieren oder bei Support- oder Fehlersuche eingreifen wird (am häufigsten oben), sowie danach, wie stark die jeweilige Ebene vom Bare Metal abstrahiert ist (am wenigsten unten).

[#image-service-stack]
.Layers of a Steadfast system. From the bottom, hardware: bare metal, filesystem: ext4 for / and optionally ZFS for /data, OS: Ubuntu LTS 64-bit server, container runtime: Docker, containers: Nextcloud file sharing app, Jellyfin media server, Wallabag article reader.
image::service-stack.svg[align="center",scaledwidth=80%]

Am häufigsten arbeite ich in den oberen Schichten – zum Beispiel beim Hinzufügen oder Aktualisieren eines Containers.
Seltener aktualisiere ich Betriebssystempakete.
Noch seltener sehe ich mir Versionen einer Konfigurationsdatei an, die auf der Festplatte gespeichert sind – dank automatischer Snapshots von ZFS.
Und schließlich, wenn mein Server ausfällt, befinde ich mich ganz unten im Stack: Ich repariere oder ersetze die Hardware.
Hier findest du die entsprechenden Abschnitte mit Details zu jeder Ebene:

* Dienste in Containern:
** <<Nextcloud: Dateisynchronisation und -Freigabe>>
** <<Jellyfin: Audio- und Videostreaming>>
** <<Wallabag: Artikel speichern und lesen>>
* container runtime:
** <<Containers == happy>>
** <<Contained services>>
* OS: <<Betriebssystem>>
* filesystem: <<Dateisystem>>
* hardware: <<Server>>

Es gibt außerdem zwei Dienste in Containern, die später behandelt werden und _nicht_ im Diagramm dargestellt sind:

* <<Watchtower: service updater>>
* <<Scratch: visual programming>>

=== Digitale Sicherheit

Lass uns die grundlegenden Werkzeuge kennenlernen, um deinen Server zu verstehen und abzusichern.

==== Categoriziere deine Daten

Zuerst solltest du deine Daten betrachten.
Es hilft, sie in zwei gängige Kategorien aufzuteilen:

===== Saidensible Daten

Beispiele: Passwörter, Kreditkartennummern, staatliche Ausweisnummern.
Empfehlungen:

. Wenn möglich, nur offline speichern.
. Falls jemals auf einem Computer gespeichert, dann verschlüsselt.
. Einfache Lösung: in einem ((Passwortmanager)) speichern.

===== Alles Andere

Beispiele: Notizen, Fotos, Dokumente, persönliche Informationen.
Empfehlungen:

. Auf verschlüsselten Medien speichern, einschließlich Backups.
. Nur mit aktueller, vertrauenswürdiger Software darauf zugreifen.
. WAN-Zugriff (Wide Area Network) auf diese Daten untersagen.

==== WAN-Zugriff

(((WAN-Zugriff)))
Sobald du deine Daten kategorisiert hast, überlege dir, wie Menschen darauf zugreifen werden.
Zuhause kannst du im Allgemeinen direkt auf deinen Server zugreifen.
Wenn du jedoch unterwegs bist oder Daten mit jemand anderem teilen möchtest, geht es um WAN-Zugriff (Wide Area Network).

(((Router)))
(((port forward)))
WAN-Zugriff ist – informell gesagt – der Fernzugriff auf Dienste und Daten, die in deinem lokalen Netzwerk (LAN) laufen.
Eine Möglichkeit, WAN-Zugriff auf einen Dienst zu ermöglichen, ist das Weiterleiten von HTTPS-Verkehr (Portweiterleitung) über deinen Router oder deine Firewall.
Portweiterleitung ohne zusätzliche Sicherheitsmaßnahmen ist zugleich riskant und bequem.

NOTE: Ziehe Alternativen zur Portweiterleitung in Betracht, wie etwa die Verwendung einer VPN.

==== Bedrohungsmodell

(((threat model)))
Gehen wir einen Schritt zurück und sprechen über Bedrohungsmodellierung.
Dein Bedrohungsmodell beschreibt, wie du Bedrohungen für deine Daten einschätzt und wie du ihnen entgegenwirken willst.
Mit einem klaren Bedrohungsmodell kannst du fundierte Entscheidungen treffen – zum Beispiel darüber, ob du den WAN-Zugriff auf deinen Server erlauben solltest oder nicht.

WARNING: Wenn du bereits weißt, dass du ein wertvolles Ziel bist (z. B. öffentliche Person, hohes Vermögen, Kriegsberichterstatter*in oder verantwortlich für einen Server mit Informationen über viele Menschen), dann gilt: Mach dich auf eine längere Reise gefasst.
Dieses Buch allein reicht nicht aus, um deinem Bedrohungsmodell gerecht zu werden.

Lass uns ein einfaches Beispiel für ein Bedrohungsmodell für die Datenklasse "alles andere" erstellen.
Überlege dir dabei folgende Punkte:

Anlagen::
  Daten, die du schützen möchtest.
Akteure / Bedrohungen / Angriffsvektoren::
  Menschen und Bots, die in böser Absicht handeln – sowie deren Angriffsmethoden.
Auch unbeabsichtigte Fehler und Software-Bugs zählen dazu.
Gegenmaßnahmen::
  Maßnahmen zur Risikominimierung, damit Angriffe weniger wahrscheinlich sind oder weniger Schaden anrichten.

Füg das alles zusammen, und du erhältst mein absolut marketingfreundliches Akronym für ein Bedrohungsmodell: A.A/B/A.G. (jede Zeichensetzung wird mitgesprochen).
Geht einem wirklich leicht über die Lippen!

==== Beispiel: WAN-Zugriff

Teste ((WAN-Zugriff)) mit diesem Bedrohungsmodell.

Anlagen::
  Dateien mit persönlichen Informationen, die in einem veralteten Dienst gespeichert sind (z. B. eine alte, verwundbare Version von Nextcloud).
Akteure / Bedrohungen / Angriffsvektoren::
  Ein Bot durchsucht Websites und findet eine URL zu einem Dienst in einem öffentlich zugänglichen Mailinglisten-Archiv.
Der Bot versucht automatisch, eine bekannte Schwachstelle im Dienst auszunutzen.
Der Angriff gelingt, und der Bot-Betreiber erhält Zugriff auf Rechenressourcen und persönliche Informationen.
Gegenmaßnahmen::
  Halte den Dienst aktuell.
Sichere die WAN-Grenze: überwache die Verkehrsdaten, setze ein ((IPS)) (Intrusion Prevention System (Einbruchsschutzsystem)) ein, und lasse den Zugriff ins ((LAN)) nur über ein VPN (Virtual Private Network) zu.
Schließe die WAN-Grenze: erlaube keinen eingehenden WAN-Zugriff.

Solltest du dich entscheiden, einen Dienst öffentlich zugänglich zu machen, helfen diese Maßnahmen, ihn zu sichern.
„Öffentliche Mailinglisten vermeiden“ ist nicht als Maßnahme aufgeführt, da es nur die URL zum veralteten Dienst verschleiert und man sich nicht auf „Sicherheit durch Verschleierung“ verlassen sollte.

[%unbreakable]
TIP: Die Absicherung auf mehreren Ebenen (Betriebssystem-Firewall, Dienst, WAN-Grenze) zeigt das Prinzip der „Verteidigung in der Tiefe“ („defense in depth“), eine gängige und sinnvolle Sicherheitsstrategie.

==== VPN

Ein ((VPN)) kann deine WAN-Grenze absichern, indem es nur authentifizierte Benutzer zulässt und eine Verschlüsselungsschicht hinzufügt.
So kannst du dich sicher in dein ((LAN)) „teleportieren“, während du remote bist.

Wenn alle deine Nutzer ein VPN verwenden können, kannst du die Ports für HTTP/S-Verkehr geschlossen halten und stattdessen nur VPN-Verkehr erlauben.
Vorausgesetzt, dein VPN-Server ist gut konfiguriert und aktuell, ist dies eine hervorragende Möglichkeit, deine ((Angriffsfläche)) zu reduzieren.

Die VPN-Technologie erhielt ein großes Upgrade durch https://www.wireguard.com[Wireguard].
Aus Nutzersicht gibt es keinen schweren Login-Prozess mehr, wie bei älteren VPNs.
((Wireguard)) ist schnell, einfach und sicher.

==== Full-disk Verschlüsselung

(((encryption, full-disk)))
Das Verschlüsseln verhindert, dass ein Angreifer Daten wiederherstellen kann.
Beim Hochfahren musst du allerdings ein Passwort eingeben.
Das ist unpraktisch, wenn es zu Stromausfällen kommt und/oder keine Fernverwaltung möglich ist.
Außerdem wird zu Recht argumentiert, dass Vollplattenverschlüsselung für einen ständig eingeschalteten Server wenig bringt: Im Normalbetrieb hast du den Entschlüsselungsschlüssel ja bereits eingegeben.

Wenn du dich für Vollplattenverschlüsselung entscheidest, wähle sie während der <<OS-Installation>> aus.
Sieh dir die vorherigen Abschnitte dieses Kapitels an, falls du bei der Entscheidung Unterstützung möchtest.

==== Mehr Tips

[#self-hoster-security-tips]
.Self-hoster Sicherheitstips
****
* Pflege nützliche, verschlüsselte Backups.
Führe Test-Wiederherstellungen durch, um deren Nützlichkeit zu bestätigen.
Siehe <<Backups>>.
* Vermeide es, Befehle als root-Benutzer auszuführen.
* Nutze Multi-Faktor-Authentifizierung.
* Setze Firewalls ein.
* Verwende starke Passwörter.
* Sei sehr vorsichtig beim Port-Forwarding oder lasse es am besten ganz weg.
* Sei wachsam bei all den üblichen Dingen: Phishing, Malware, SMS-Spoofing und Social-Engineering-Angriffen.
** Sei vorsichtig mit Links und Anhängen in E-Mails.
** Installiere keine nicht vertrauenswürdige Software. Always use HTTPS.
** Nutze bei deinem Mobilfunkanbieter eine spezielle Passphrase als zusätzliche Authentifizierungsebene.
** Hinterfrage Dringlichkeit und verdächtige Anfragen kritisch.
* Leite unbekannte Anrufe auf die Mailbox um.
* Achte auf Datenpannen und schütze deine Identität.
** Sperre deine Kreditinformationen nach einem Datenleak.
* Informiere dich über Kompartimentierung (Isolation) und das Prinzip der geringsten Privilegien.
****

Zusätzliche Lektüre:

* https://oreilly.com/library/view/personal-cybersecurity-how/9781484224304/[Personal Cybersecurity: How to Avoid and Recover from Cybercrime] by Marvin Waschke
* https://modernprivatelife.com/how-to-choose-privacy-threat-model/[Personal Privacy Threat Modeling (With LOTS Of Examples)] by Eliza
* https://arstechnica.com/information-technology/2017/07/how-i-learned-to-stop-worrying-mostly-and-love-my-threat-model/[How I learned to stop worrying (mostly) and love my threat model] by Sean Gallagher

=== Dateisystem

(((ZFS)))
Ich empfehle (und werde demonstrieren), mit einem einzigen ((ext4))-Dateisystem zu beginnen und optional einem ZFS-Dateisystem.
ext4 ist das stabile, einfache und standardmäßige Dateisystem für Ubuntu.
ZFS (ursprünglich: Zettabyte File System) bietet Verschlüsselung, leichte Snapshots und ((RAID)) (redundante Anordnung kostengünstiger Festplatten).

Optional kannst du ZFS für den Speicher (`/data`) auf deinem Server verwenden, wie unter <<ZFS setup>> beschrieben.
Für die Root-Partition (`/`) empfehle ich stattdessen ext4 zu verwenden, um:

* So nah wie möglich an der Standard-Ubuntu-Installation bleiben
* Docker-Dateisystem-Müll vermeiden
** Wenn `/var/lib/docker` auf ZFS liegt, werden viele Docker-bezogene Dateisysteme erstellt, die die Ausgabe von `zfs list` etwas unübersichtlich machen
* ZFS-Snapshots des Betriebssystems vermeiden, da
** wir sie nicht brauchen
** das Betriebssystem außerhalb der ZFS-Verzeichnisse liegt
** wir das Betriebssystem nicht verändern werden – Änderungen werden upstream verwaltet (z. B. bei Paketupdates oder über mario)

Docker-Volumes (persistente Container-Daten) werden auf ZFS gespeichert.
Das Dateisystem des ((Container))s – also alles außer den gemounteten Volumes mit persistenten Daten – ist flüchtig (ephemeral) und liegt auf ext4 unter `/var/lib/docker`.
Um mehr über ZFS zu erfahren, siehe:

* https://arstechnica.com/information-technology/2014/01/bitrot-and-atomic-cows-inside-next-gen-filesystems/[Bitrot and atomic COWs: Inside „next-gen“ filesystems] by Jim Salter
* https://arstechnica.com/information-technology/2020/05/zfs-101-understanding-zfs-storage-and-performance/[ZFS 101—Understanding ZFS storage and performance] by Jim Salter
* https://wiki.debian.org/ZFS[ZFS (Debian wiki page)] by various authors

Weitere ZFS-Konzepte, die es sich zu lernen lohnt: Fragmentierung, ARC (Adaptive Replacement Cache), Resilvering, Scrubbing, `ashift` und `recordsize`.

=== Betriebssystem

(((Betriebssystem)))
(((Ubuntu)))
((Linux)) ist eine beliebte und vernünftige Wahl für Self-Hosting. Ich empfehle einen 64-Bit-Ubuntu-Linux-Server mit mindestens 2 GB Arbeitsspeicher und 30 GB Speicherplatz.
Ubuntu ((LTS)) (Long-Term Support)-Versionen sind am stabilsten, und ich empfehle genau diese.
Steadfast bezieht sich speziell auf 24.04, die LTS-Version von April 2024.
Version 24.04 ist heute stabil und wird bis April 2034 Updates erhalten, was viele weitere Jahre Stabilität verspricht, bevor Steadfast überarbeitet werden muss.
Die Installation des Betriebssystems ist im Allgemeinen schnell und schmerzlos, siehe <<OS-Installation>>.

==== Personalisierung

Es ist gute Praxis, Anpassungen am Betriebssystem möglichst gering zu halten und sorgfältig zu dokumentieren, wenn man von einer Standardinstallation ausgeht.
Das erleichtert die Wartung, einschließlich eventueller Neuinstallationen.
Nicht ständig am Server herumzubasteln erfordert Disziplin, besonders für altgediente, hands-on Systemadministratoren wie mich.

Versuche, es zu vermeiden, dich per SSH direkt auf den Server einzuloggen und dort Einzeländerungen vorzunehmen.
Du wirst lernen, stattdessen die Konfigurationsdateien von mario zu bearbeiten und den Server neu zu provisionieren (siehe <<_mario>>).

Natürlich kannst und solltest du dich weiterhin per ((SSH)) auf den Server verbinden, aber versuche dann, nur Lesezugriffe oder nur ausnahmsweise Schreibzugriffe auszuführen.
Ich mache oft erst etwas manuell, mache es rückgängig und erledige dann denselben Schritt mit mario, um sicherzustellen, dass das Ergebnis wie erwartet ist.

****
Beispiele für serverseitige Leseoperationen:

* Ressourcenverbrauch pro Container anzeigen: `sudo docker stats`
* Container-Logmeldungen verfolgen (ausführen im Verzeichnis mit einer `compose.yml`-Datei): `sudo docker compose logs -f`
* Server-Gesundheit prüfen: `date; tail /proc/pressure/*`

Beispiele für serverseitige Schreiboperationen:

* Betriebssystem-Pakete aktualisieren: `sudo apt full-upgrade`
* Berechtigungen für einen Ordner ändern: `chmod 0700 ~/bin/`
****

Beginne mit einer Checkliste für die „monatliche Wartung“, wie sie in <<Server maintenance>> zu finden ist.
Nimm diese schreibenden (read-write) Operationen in deine Checkliste auf.
Führe schreibende Operationen nach Möglichkeit mit mario durch.

Verwende stets `sudo`, um privilegierte Befehle auszuführen, anstatt dich direkt als `root` anzumelden.
So wird jeder Befehl zusammen mit Zeitpunkt und ausführender Person in `/var/log/auth.log` protokolliert.

Upgrades können automatisiert werden.
Das ist sinnvoll, sobald man eine gewisse Skalierung erreicht hat – vorausgesetzt, man hat Vertrauen in und Kontrolle über die Quelle der Updates.
Ich persönlich führe Betriebssystem-Upgrades meist manuell durch, da ich nur wenige Systeme betreue. Der Aufwand ist dadurch gering und selten, und das Aktualisieren eines Pakets kann Tests oder manuelle Eingriffe (z. B. einen Neustart) erfordern.
Aus ähnlichen Gründen installiere ich auch das Betriebssystem selbst von Hand.

Mein Betriebssystem ist eher ein Haustier als ein Nutztier (siehe „cattle vs. pets“ im <<Glossary>>).
Vielleicht ist es sogar ein *Haustier-Phönix*:
Wenn es stirbt, lässt es sich relativ leicht aus der Asche wiederbeleben.
Es wird regelmäßig gesichert, es gibt nur wenige manuelle Schritte – und alle manuellen Schritte sind sorgfältig dokumentiert.

=== Contained services

mario uses ((Docker)) to run services in containers.
Docker is but one of many valid choices for how to isolate and run services.
((VM))s are also often used for this purpose.
See <<Containers == happy>> for a comparison of the two.
If you're interested in VMs (instead of or in addition to containers), check out https://proxmox.com[Proxmox].

((Kubernetes)) also works well for running services.
Try Kubernetes (especially one of the interesting micro-versions) if you are more familiar or interested in that.
I found it to be overkill.
If I needed high availability via clustering I'd be more likely to use Kubernetes.
If one computer in a Kubernetes ((cluster)) breaks, services can automatically migrate to working hardware in the cluster.
Regardless of your tech choices, set a clear expectation to your users as to how long your server might be down when something breaks.

(((isolation)))
Docker balances features and usability well, making it easy to run one service in isolation.
((Docker Compose)) adds the ability to define and run the groups of processes necessary to support a whole service (e.g. a web server and its database).
Kubernetes can do this too, along with everything you _don't_ need to learn unless you are building out an entire virtual data center.
Docker Compose is a good fit for a single-server setup.

It is also good to avoid intermingling services and their dependencies along with everything else on the server's primary storage.
Having everything on one filesystem is easy at first, for one service.
https://en.wikipedia.org/wiki/Dependency_hell[It gets more complicated the more services you add].

Many of the desperate self-hoster support requests I see in FOSS communities are about incompatibilities between this or that version of PHP or relational database between two different services.
Docker mitigates this by bundling dependencies.
Each Docker image is basically a complete filesystem (sans kernel), so a service's image would always include the correct PHP version.
Another image would be used to create the database, if/as necessary.

It's worth lingering on bundled dependencies for a minute.
If dependencies are clothes, a Docker ((container)) is a strong and cheap suitcase with all the clothes you need for a week's travel.
You check your suitcase and board the train, then rest easy knowing your suitcase is tucked neatly, separately, next to all the others.
Docker containers are suitcases while the old way is everyones`' unfolded clothes in a giant pile in the caboose.

(((image)))
Containers are created from images.
An image is the blueprint to magic a fresh new suitcase (container) into existence, all packed and ready with the right clothes for your trip.
An image is built once, stamped with an identifier, and shared, where it can act as the basis for countless consistently-behaving containers.

Images are defined by a file named `Dockerfile`.
The `Dockerfile` should be tracked in source control.
Since mario uses Docker Compose, another important file is `compose.yml`.
Each service will have its own `compose.yml` file.
These should be kept in source control too.
For sysadmins these conventions provide ((reproducible)) images and containers.
For users: predictable, reliable services.

(((cattle vs. pets)))
Practice treating containers as temporary things.
You'll gain confidence in your system by creating and destroying them frequently, and you'll enjoy the speed and ease of doing so.
Think:

* ephemeral
** containers are temporary
** temporary containers provide robust, reproducible services
* cattle, not pets
** hand-managed VMs are burdensome pets
** apologies to the cattle--in this analogy they are expendable
* stateless
** persistent data can and must be defined explicitly
* phoenix server
** a term by Kornelis Sietsma describing repeated server destruction and re-creation

=== Reverse Proxy

A ((reverse proxy)) sits in front of containers and directs traffic to the right service based on arbitrary rules.

Say you've purchased the domain example.com and want to host Nextcloud at cloud.example.com and Jellyfin at jellyfin.example.com.
Your sever uses a reverse proxy and a single IP address to direct incoming traffic to each of these services based on the hostname.

mario uses Traefik for its reverse proxy.

==== Traefik architecture

Here's a bit about how ((Traefik)) works and how it works with Nextcloud and other self-hosted web services.

We want ((HTTPS)) requests to port 443 bound for cloud.example.com to reach the Nextcloud service.
Study the included Traefik architecture diagram to better understand this process along with the mario sources.

[#image-traefik-architecture]
.Traefik architecture diagram showing how a request reaches a service. From the MIT-licensed Traefik source code. Credit to Peka for the gopher logo, licensed CC-BY-3.0.
image::traefik-architecture.png[]

(((router, Traefik)))
In the mario source code (or the snippets appearing later), look at the `compose.yml` files for Traefik and Nextcloud, which include:

* the `websecure` ((entrypoint)), where we accept HTTPS traffic on port 443
* the `app` service definition for Nextcloud, which includes Traefik routing labels
* the `Host(...)` rule in the `nc-https` router

[%unbreakable]
NOTE: The symbols `app`, `websecure`, and `nc-https` are arbitrary.
I used short names to keep them from wrapping across lines.
You may wish to use longer, more descriptive names.

The routing labels wire together the entrypoint and router with the service under which they are defined.
That is: `websecure` to `nc-https` to `app`.

These two snippets of the mario source show how we set up Traefik for Nextcloud.

.Traefik configuration snippet (🏠 admin computer)
[source#traefik-config,yaml]
----
# from traefik/compose.yml
services:
  reverse-proxy:
    command:
      - --entrypoints.websecure.address=:443 <1>
----

<1> Define entrypoint `websecure` on the `reverse-proxy` service, accepting traffic over port 443.

.Nextcloud configuration snippet (🏠 admin computer)
[source#nextcloud-config,yaml]
----
# from nextcloud/compose.yml
services:
  app:
    labels:
      - "traefik.http.routers.nc-https.entrypoints=websecure" <1>
      - "traefik.http.routers.nc-https.rule=Host(`cloud.example.com`)" <2>
----

<1> Connect the `websecure` entrypoint with the `nc-https` router on the `app` service.

<2> Use the hostname rule with the `nc-https` router.

Each self-hosted service will have its own router.
Other web services will also use the `websecure` entrypoint.

HTTPS encryption is configured using other labels on the Traefik container.
See <<Encryption certificates>> for details.

== Implementation

Now we're ready to stand up the first three layers in <<Service stack>>: Hardware, filesystem, and OS.
I'll start by providing tools to evaluate services, then continue to OS installation and server maintenance.

=== Service plan

Services are long-running software programs on your server.
Some have an interface, some run in the background on a schedule.
„Web services“ are the ones you can connect to using a web browser or other tool speaking HTTP.

==== Choose services

Start by reviewing your earlier needs and plans and use the material below to guide your decisions on which services you'll run.
You may also skip ahead to <<Hardware vorbereiten>> to continue on the path of using the services mario installs by default, then return to this section when you're considering other services to add.

===== Good for self-hosting

You'll find some services are better choices to self-host than others.
The good ones will likely share at least some of these traits.

.Traits of Good Self-Hosted Services
[#traits-of-good-services]
****
* Easy to install and self-hosting instructions exist.
* Works with your preferred deployment method, e.g. has a popular and well-maintained Docker image, has instructions for integrating with ((Docker Compose)) and Traefik.
* Community uses tools such as moderated chats, forums, news, mailing lists, and meetups.
* Recent source code activity: releases, contributions, news.
* Uses a FOSS software license.
* Transparent about owners and sponsors.
* Public roadmap, issue tracking, continuous integration, working demo, build scripts, bug/security bounties.
* If you experience a problem you're able to easily find more information about it (e.g. existing issue in tracker, workarounds) by searching the web.
* Well-organized, elegant code.
* Useful and up-to-date documentation.
* Mentions and compares itself with other similar services.
* Well-documented, useful, and complete API.
* Flexible and extensible (easy to customize and extend with plugins and such).
****

See also: <<solution-viability-checklist>> in <<Alternativen zu mario>>.

These traits are based on standard industry practice as well as my personal values and preferences.
Your own list may differ if, for example, you don't prefer FOSS licensing or do prefer a particular programming language.

===== Bad for self-hosting

Here are some indications a self-hosted service might be one to avoid.

.Traits of Bad Self-Hosted Services
[#traits-of-bad-services]
****
* Unpopular, inactive, or poorly maintained.
** Few maintainers / contributors.
** Maintainers are inattentive to contributors.
* Includes telemetry (phones home, collects statistics or usage data), especially without your consent and/or enabled by default.
* Has known security vulnerabilities.
* Confusing or opaque governance, roadmap, licensing, source control, contribution intake, issue tracking.
* Sprawling complexity.
* Difficult to fork.
* Only geared towards enterprise: self-hosting instructions are complex or missing entirely.
* Frequent annoying upsells/nags.
* Intentional vendor lock-in.
* Depends on closed/proprietary standards/services.
* https://en.wikipedia.org/wiki/Open-core_model[Open core].
****

(((Nextcloud)))
I'm going to pick on Nextcloud here a bit.
Nextcloud has far more good traits than bad, but these are still worth mentioning.

(((fork)))
First, their apparently non-FOSS build script.
https://help.nextcloud.com/t/build-bzip-and-package-from-git/58341/2[Nick's explanation] for this makes sense: it is more convenient for them to hardcode secrets directly in the build script and keep the whole thing secret.
But hardcoded secrets are bad practice, it may be an AGPL license violation to hide a build script, and it makes forking harder.
It's good practice to visualize succession, to be prepared for an eventual fork and change of ownership.
Nextcloud is a fork of ((ownCloud)), after all (see <<Nextcloud vs. ownCloud>>).

Second, sprawling complexity.
„Nextcloud“ is not one thing, it is a collection of _many_ software projects and services under various degrees of control by a single company.
This complexity makes forking costly and time-consuming.
Even switching between extant forks (say, migrating back to ownCloud from Nextcloud) may be complex.
They are clearly _not_ trying to lock in customers, but the complexity itself may ultimately have that effect.

==== Map services to resources

Here's an early, rough resource planning table I used.
You can use this pattern to estimate your own resource needs.
I go into detail about a few of these services later in the book.

[%unbreakable,cols="4,4,3,2,2",id=example-tally]
.Example tally of services to hardware resources
|===
|Service |Purpose |Isolation |Cores |RAM

|jellyfin |stream music |Docker |2 |2 GB
|kahoot-clone |quiz game |Docker |0 |0 GB
|poller |polls |Docker |0 |0 GB
|backuppc |backups |none |0 |0 GB
|taskd |task tracking |Docker |0 |0 GB
|sftp |file transfers |none |0 |0 GB
|syncthing |file sync |none |1 |1 GB
|nextcloud |file sharing |Docker |2 |2 GB
|minetest |game server |Docker |4 |8 GB
|irssi |chat client |none |0 |0 GB
|jitsi |video calls |Docker |2 |2 GB
|wallabag |article saver |Docker |1 |1 GB
|===

„Cores“ represents relative peak compute requirements.
RAM: peak memory.
These were rough estimates based on published documentation.
The estimates turned out to be accurate enough.
I could see right quick I'd need something more powerful than the latest available Raspberry Pi.
See <<Server>> for more lessons learned about resource requirements.

=== Hardware vorbereiten

It's called __hard__ware because these problems are _hard_.
That's fun to say and, in my experience, false.
While there is a learning curve for understanding basic computer hardware components and hardware can certainly fail, there are plenty of wonderfully positive aspects of hardware. For example:

* Hardware is tangible and behaves consistently.
* Just plug it in, turn it on, and it'll probably work.
* When it does work, it is quite satisfying.

==== Server

You'll need a server.

(((compute)))
You can always pay for „compute“ in someone else's cloud, but it'll end up costing more in the long run.

If you're in a hurry, you can start with pretty much any old desktop or laptop, or your own VM running on either.
Use something more powerful and expandable than a Raspberry Pi, though.
What if your users love it?
How will you increase storage?
What about bursty workloads?
If you start with something too small you won't have enough speed nor expandability.

I've worked with quite a few different servers and I did my homework for this self-hosting adventure, so I had a decent idea of what I wanted.
I chose something powerful, cheap, and fast with plenty of storage and room to grow.
I sought professional commodity hardware for its replace-ability.
It can handle a reasonable amount of bursty compute needs, including building Docker images, flurries of user activity, and some generative ((AI)) (even without a GPU).

I found a used refurbished 1U rackmount server on eBay for about $1,000.
This is sometimes called „off-lease enterprise hardware“.
A 1U server is one https://en.wikipedia.org/wiki/Rack_unit[rack unit] tall, like a long pizza box.
Tech companies dump these by the truckload so you can usually find a good deal.
Mine has two 24-core CPUs and 128 GB RAM.

[#image-racked-server]
.DIY rackmount server attached to garage ceiling. It's fun to look at and is out of the way, but I need a ladder for maintenance and it weighs about 50lbs.
image::racked-server.jpg[align="center"]

The fans are _way_ louder than a desktop, especially when it is under load.
It is supposed to have decent ventilation, temperature and humidity regulation yet has so far been extremely hardy even below freezing and above 100°F for extended periods of time.
(((IPMI)))
It has several enterprise features to ease maintenance such as redundant power supplies, hot-swap drive bays, lots of sensors, and remote management via a web browser or IPMI.

Power consumption averages 130W, or about 1,140kWh per year; roughly $138.15 in Seattle.
That's about as much as a bright incandescent light bulb, and it's a bit wasteful for one user.
Five users though?
~228kWh/year each.
That's less than the cloud server hardware required for a mobile device making use of Google's or Apple's clouds.
Further reading on this topic:

* https://science.time.com/2013/08/14/power-drain-the-digital-cloud-is-using-more-energy-than-you-think/[The Surprisingly Large Energy Footprint of the Digital Economy] by Bryan Walsh
* https://theguardian.com/sustainable-business/2014/sep/10/energy-consumption-behind-smart-phone[The spiralling energy consumption behind your smart phone] by Betsy Reed
* https://increment.com/energy-environment/the-secret-energy-impact-of-your-phone/[The secret energy impact of your phone] by Owen Williams

A rackmount server like mine can handle far more than 5 users, assuming they aren't all trying to transcode video.

It also makes a great heated perch.

[#image-bird-on-server]
.Bird perched on server.
image::bird-on-server.jpg[align="center",scaledwidth=50%]

==== Admin computer

(((admin computer)))
It's helpful to have a separate computer from your server to make changes.
I usually run mario using a laptop as my admin computer.

==== Test devices

Your users will have their own computers and mobile devices (their _clients_).
Maintain a couple of different clients so you have comparable environments to better help your users.

(((dogfooding)))
TIP: Be a user of the services you self-host.
This is _dogfooding_.
Dogfooding keeps you honest and helps you empathize with others.

==== Hard drives

(((ZFS, snapshots and)))
I use ((HDD))s (hard disk drives) for data storage, mainly as a cost-saving measure vs. public cloud storage or ((SSD))s (solid-state drives).
The cost of public cloud ((block storage)) far exceeds the gigabyte-hour cost of my HDDs.
I priced out one month of 5TB HDD block storage on AWS at $228.10.
With ZFS I'm also taking a snapshot (bascially a full local backup) _every fifteen minutes_.
One month's worth of hourly snapshots (the closest comparable I could find) is another $310.68 on AWS.
That's $535.67 total, which is about what I spent on my drives.
So I broke even in a month and the drives should last _years_.

(((RAID)))
For redundancy I recommend using two of the same drive, mirrored (RAID 1).
This also increases read performance (for most reads) and halves usable storage space.

HDDs are plenty fast when measured from the standpoint of self-hosted service response time.
The OS (operating system) and services do well at caching data served, assuming the server has sufficient RAM.
Remote backups can take a while, and that's fine.

I use one SSD for the OS and everything besides my photos/documents/etc, since start-up time for the OS is important and realizes far less benefit from the OS filesystem cache (especially at boot time).

(((data sovereignty)))
An interesting alternative to HDDs for special cases is ((object storage)).
It's a very scalable cloud-based unstructured key-value store that the OS can't use directly, but Nextcloud can.
There are many aspects to consider when comparing the two options, such as:

* cost of storage and ((egress)) (download)
* control, autonomy, sovereignty
* software support for object storage
* direct access to data
* speed and means of access
* network availability
* backups, versioning, security

I went with HDDs for direct, local access to my data.
I really wanted to know exactly where they were stored and for ultimate flexibility when I change or try new services.
Most of my services require direct access anyway.

==== Networking

If you are hosting at home, you need a reliable WAN (wide-area network) connection if you want to be able to connect from other places besides your ((LAN)).
Use wired ethernet cables to your server, not Wi-Fi.
A wired LAN is more reliable and easier to troubleshoot.

===== Minimum requirements

(((ISP)))
Here are some typical minimums for hosting at home:

* 100mbps up / 100mbps down ISP connection
* Cat 5 ethernet cable (for your server)
* 802.11ac Wi-Fi (for clients)

I just made these up based on what works for me, then doubled that so you have some room to grow.

===== Home router configuration

Learn how to configure your ((router)).
Keep it up to date and maintain a strict ((firewall)) with only the necessary ports open / forwarded.

[%unbreakable]
CAUTION: Port forwarding allows inbound connections through your WAN boundary to your server.
Read <<Digital security>> before forwarding any ports.

Make a sketch to better understand your network.
Here's a simple diagram I created using https://asciiflow.com to plan cabling and visualize the flow of traffic through my network devices:

ifdef::backend-html5,backend-pdf[]
[#image-WAN-to-LAN-traffic]
.WAN into LAN traffic flow diagram.
image::WAN-to-LAN-traffic.svg[align="center",scaledwidth=80%]
endif::[]
ifdef::backend-epub3[]
[#image-WAN-to-LAN-traffic]
.WAN into LAN traffic flow diagram.
image::WAN-to-LAN-traffic.png[,472,320,align="center"]
endif::[]

(((IPMI)))
Arrows represent ethernet cable.
The router provides electricity to the mini switch using PoE (power over ethernet).
The server has two NICs (network interface cards): one for the OS and everything within (including all services), and one for a network connection to the embedded OOB (out-of-band) remote management computer with IPMI (Intelligent Platform Management Interface).
WAN traffic is allowed to flow to the main NIC and not to the IPMI NIC.

==== Electricity

Use a surge protector.
Consider a UPS (uninterruptible power supply) if your power at home is unreliable.

==== Physical security

Keep your server safe, similar to other valuables in your home.
At the very least, restrict physical access.

=== OS-Installation

Here's a guide to setting up your server.
The OS install takes about five minutes if everything proceeds smoothly.
Steps are omitted for brevity when the default is acceptable.

NOTE: As you install the OS, think ahead to disaster recovery.
Take notes and visualize yourself repeating the process precisely.
At each step in the interactive Ubuntu installer, accept the default or write down your choice.

. *Install Ubuntu* 24.04 LTS server.
Refer to https://ubuntu.com/tutorials/install-ubuntu-server[this tutorial] for step-by-step instructions.
. *Use a static LAN IP address* when configuring networking.
You may also be able to leave this as the default (DHCP/dynamic), and use your LAN router to assign an IP address that doesn't change.
. Optional: use full-disk encryption.
See <<Full-disk encryption>>.
. *Note the username and password* when you set up a user account (called a „Profile“ in the installer). You'll need these soon.
. *Install OpenSSH server* when prompted to do so.
. *Do not install Nextcloud or Docker*, let mario install these later.

Congratulations, you just installed Linux!
Next steps:

. Optional: after installing Ubuntu, add two HDDs and format them with ZFS.
See <<ZFS setup>>.
. Download mario onto your admin computer (a separate computer from your server). See <<Weitere Ressourcen>>.
. Run mario on your admin computer to provision your server. See <<_mario>>.

==== ZFS setup

(((ZFS, setting up)))
The OS takes care of itself pretty well.
For more robust data storage, you can add a couple of HDDs and manage them with ZFS.

ZFS adds many features and some complexity.
The learning curve is worth it.
The guide below walks through creating a simple pool of two mirrored drives, visible at `/data`.
This is a reasonable starting point, providing increased fault tolerance and better read performance than a single drive.

On the server, run these commands as `root` (hint: use `sudo su -` first).
The code below assumes you started with one drive for the OS, the OS called that drive `/dev/sda`, then you added two more drives, and those were assigned `/dev/sdb` and `/dev/sdc`.
Adjust these as necessary, using `lsblk` to figure out yours.

// This code snippet is wrapped by Vim with textwidth=75 since this just happens to be what fits in the current print book margins. 😬

.ZFS setup (🚀 server)
[source#zfs-setup,bash]
----
# Create partition tables.
parted /dev/sdb mklabel gpt
parted /dev/sdc mklabel gpt

# Create ZFS main mirrored pool and set attributes (for all future datasets
# in this pool).
zpool create -O mountpoint=none main mirror /dev/sdb /dev/sdc
# For performance.
zfs set atime=off main
# To save space.
zfs set compression=on main
# For security.
zfs set exec=off main
zfs set setuid=off main
zfs set canmount=off main

# Create encrypted dataset in "main" pool. This is the "parent" dataset, we
# can easily add more later and they'll all be encrypted.
openssl rand -base64 32 > /root/secure-dataset-key
zfs create -o encryption=on -o keyformat=passphrase \
    -o keylocation=file:///root/secure-dataset-key main/secure
zfs set canmount=off main/secure

# Create usable (mount-able) dataset.
zfs create -o mountpoint=/data main/secure/data

# This might not be necessary if you _never_ want to execute anything in
# /data. I found I needed it for something within a container (ffmpeg, I
# think). You can start with exec=off and turn it on later if you want.
zfs set exec=on main/secure/data
----

Here are a few commands to see details about what you just created.
These do not require root access.

.show ZFS details (🚀 server)
[source#zfs-details,bash]
----
# Examine pools.
zpool status
zpool list

# Examine datasets.
zfs list
----

On Ubuntu 24.04 LTS, more steps are required to automatically mount this new filesystem when the server boots.
What follows is from the `zfs-mount-generator(8)` manual page, with a few corrections.
These must be run as `root`.

.ZFS mount on boot setup (🚀 server)
[source#zfs-mount-on-boot,bash]
----
# enable tracking for the pool
mkdir /etc/zfs/zfs-list.cache
touch /etc/zfs/zfs-list.cache/main

# enable the tracking ZEDLET
systemctl enable zfs-zed.service
systemctl restart zfs-zed.service

# trigger cache refresh
zfs set relatime=off main/secure
zfs inherit relatime main/secure

# re-run systemd generators and reboot
systemctl daemon-reload
reboot
----

=== Server maintenance

(((maintenance, server)))
I use short monthly and yearly maintenance checklists.
I update my checklists about as often as I use them.
Here are examples you might use as starting points.

.Checklist: Monthly Maintenance
[%unbreakable#monthly-maintenance]
****
* [ ] Upgrade OS packages.
* [ ] Check storage space remaining.
* [ ] Back up router configuration.
****

Note that Ubuntu server comes with the `unattended-upgrades` package, which automatically installs security updates for you.
You may want to instead have „confirm OS package upgrades worked“ on your checklist.

Yearly tasks are typically more work and involve aspects of a system and its dependencies which should change less often.

.Checklist: Yearly Maintenance
[%unbreakable#yearly-maintenance]
****
* [ ] Test restore from backup.
* [ ] Review and improve threat model.
* [ ] Open server chassis and vacuum dead spiders.
****

The following sections cover specific maintenance tips and tricks.

==== Hardware failure

Plan on hardware failure.
If you can afford it, the easiest way to reliably run one server is to _buy two identical servers_.
Use the second for parts or a ready as-is replacement machine (also called a „cold spare“).

==== Software updates

Keep your server up to date.
For the OS:

.upgrade packages (🚀 server)
[source#upgrade-packages,bash]
----
sudo apt update && sudo apt full-upgrade
----

This will update local package information and--if that succeeded--upgrade the OS.
Root access is required, hence `sudo`.
This is relatively safe and typically requires little to no interaction besides a confirmation to proceed.
A reboot may be required afterwards (e.g. when the kernel is upgraded).
The server will say if a reboot is required upon login.

Each service in <<Services>> includes a „Maintenance notes“ section with update instructions.
Container images can be updated by hand with ((Docker Compose)) or automatically by ((Watchtower)).
See <<Watchtower: service updater>> for details.

==== Monitoring

Monitor server health.
Check free disk space with `df -h`.
If things feel slow, check PSI (pressure stall information) with

.check PSI (🚀 server)
[source#check-psi,bash]
----
tail /proc/pressure/*
----

`atop` will also show PSI values.
If your PSI check shows high resource usage, try `docker stats` to see resource usage per container.
That should help you narrow down the issue to specific services.

If you are using ZFS, you can use `zpool iostat` to see input/output statistics for your storage pool(s).

At the host level, you can use `htop -d 100` to see stats for all processes and threads.
Follow all logged events for the host with `journalctl -f`.

==== Backups

Having useful backups is one critically important practice you'll rarely get credit for doing well, only blame if it is done poorly.

Check your backups regularly to make sure they work.

(((ZFS, snapshots and)))
Make consistent backups of everything on your server, such that the services running are unaware they are even being backed up.
For example: create a ZFS snapshot and back _that_ up.

Backing up using ZFS snapshots _can_ still cause problems.
For example, ZFS doesn't guarantee consistent state of backed-up data for running programs.
Say you restored a MariaDB database from backup.
Unless you flushed and locked tables before taking that ZFS snapshot, MariaDB might have been in the middle of a write operation with in-memory data not yet flushed to disk.
It would need to recover, and the data MariaDB was trying to write may be lost.
This manner of data loss is rare, and the risk is acceptable for the typical homelab.

[%unbreakable]
TIP: Create ((backups)) following the 3-2-1 rule of thumb: make *3* backups.
Store at least *2* local copies on different media.
Have *1* remote backup.

(((backups, using restic for)))
(((backups, using Borg for)))
(((Borg)))
(((restic)))
I recommend a backup strategy combining ZFS snapshots with either https://restic.net[restic] or https://borgbackup.org[Borg] for sending them offsite.
https://reddit.com/r/BorgBackup/comments/v3bwfg/[Here's a decent comparison of restic vs. Borg].

Here are some example commands demonstrating how to back up a ZFS filesystem.
You can use these to get started writing your own backup script.

.example backup script (🚀 server)
[source%unbreakable#example-backup-script,bash]
----
snapName=$(date -I)-backup

sudo zfs snapshot main/secure/data@$snapName <1>

sudo restic backup /data/.zfs/snapshot/$snapName <2>

sudo zfs destroy -R main/secure/data@$snapName
----

<1> Running this command to create a snapshot takes 0.040 seconds on my server.
Once it is done, a new read-only folder will appear under `/data/.zfs/snapshot` containing the snapshot.

<2> This line assumes you have installed and configured restic.
It can send your snapshot offsite, following the 3-2-1 rule of thumb.

== mario

(((Ansible)))
((mario)) is a tool I built to help you set up and maintain a server.
It is mainly a wrapper around the well-established https://ansible.com[Ansible] system provisioner.
Everything I'll do with mario can also be done manually, directly on the server.
The advantage of using mario instead is that each change (say, installing a package) will be made consistently and with an audit trail.
The real payoff of this practice is realized when you collaborate with others, including your future self.
It's not often easy to remember what you did a year ago and why.

Once your server is online following <<OS-Installation>>, use mario to configure and start services.

Please download the source code (see <<Weitere Ressourcen>>).
It'll be helpful to have this handy so you can follow along as you read.

mario can be found alongside this book, in the `mario/` folder.
The `provision.sh` script is in `ansible/`.

=== mario philosophy

mario is a practical learning tool.
It comes with sensible, tested defaults.
It automates some of the tedious, confusing steps of setting up services on a server.
mario is not a supported and production-ready software product.
It'll get you started, that's all.
Continue with it if you like or just use it to fast-forward your personal cloud setup.
Something else does or will do its job better.
Here are some suggestions to get the most out of mario.

The first time you run mario, follow the instructions as closely as possible.
Many assumptions are made so it works „out of the box“, and it is meant to be easily customizable.

mario configuration files are declarative: They contain the _state_ you want your server to end up at, not all the individual commands you'd run manually to achieve the same state.
mario's `provision.sh` runs Ansible, and Ansible runs the commands for you on the server (like running `chmod` on a file) in a predictable and repeatable manner.
The desired end state, as declared in the configuration files, is reached and confirmed by Ansible.

(((idempotent)))
(((provision)))
After getting mario up and running successfully once, run it again!
Provisioning with mario is reassuringly idempotent: The system will not change in any meaningful way after the desired state is reached.
Once `provision.sh` completes successfully, it may be re-run to confirm the server is still in the desired state.
Then, start tinkering.
You can find some ideas in <<Exercises>>.

If you are familiar with and prefer using VMs, you may want to first create a VM and run mario against that until you're ready to run mario pointed at your real server.
Or perhaps your real server _is_ a VM--that'll work fine too.

=== SSH setup

mario runs on your ((admin computer)) and expects to be able to connect directly to your server using SSH.
Here's how to get this working.

First, map your server IP address to a convenient name.
Using the IP address from <<OS-Installation>>, add a line like this to your hosts file (e.g. `/etc/hosts`):

.line to add to hosts file (🏠 admin computer)
[source%unbreakable#line-for-hosts,text]
----
192.168.1.100	mario_server
----

Confirm you're able to ping the server using the name `mario_server`.
Here's what it looks like when it works:

.test ping server (🏠 admin computer)
[source%unbreakable#test-ping-server,text]
----
$ ping mario_server
PING mario_server (192.168.1.100) 56(84) bytes of data.
64 bytes from mario_server (192.168.1.100): icmp_seq=1 ttl=64 time=0.316 ms
64 bytes from mario_server (192.168.1.100): icmp_seq=2 ttl=64 time=0.535 ms
64 bytes from mario_server (192.168.1.100): icmp_seq=3 ttl=64 time=0.178 ms
^C
--- mario_server ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2041ms
rtt min/avg/max/mdev = 0.178/0.343/0.535/0.146 ms
----

Next, make your SSH client pass along the correct username when you run `ssh mario_server`.
Here's an example client configuration template for ((OpenSSH)).
Replace `your-username` with the account username on your server.

.customize OpenSSH client configuration (🏠 admin computer)
[source%unbreakable#customize-openssh-client,text]
----
Host mario_server
  User your-username
----

You can add that to `~/.ssh/config`, adapting as necessary for the SSH client you use.
Test it by running `ssh mario_server`.
You may see something like this:

.SSH host fingerprint prompt (🏠 admin computer)
[source%unbreakable#ssh-host-fing,text]
----
The authenticity of host 'mario_server (192.168.1.100)' can't be established.
ECDSA key fingerprint is SHA256:o2kUkvSP3JG9PTt/Ju11FWKkCpTJCB4rY3jQvImtRNw.
Are you sure you want to continue connecting (yes/no/[fingerprint])?
----

If the IP address is correct, it is safe to assume the LAN-only server you just created is the same one you're trying to connect to now.
Go ahead and continue with kbd:[yes+Enter].
If you want to be super careful, run one of these commands on the server and confirm the fingerprints match:

.show SSH host public key (🚀 server)
[source#show-ssh-host-pubkey,bash]
----
# use this if you saw "ECDSA key fingerprint..." earlier
ssh-keygen -lf /etc/ssh/ssh_host_ecdsa_key.pub

# use this if you saw "ED25519 key fingerprint..." earlier
ssh-keygen -lf /etc/ssh/ssh_host_ed25519_key.pub

# use this if you saw "RSA key fingerprint..." earlier
ssh-keygen -lf /etc/ssh/ssh_host_rsa_key.pub
----

Next, set up public key authentication.
If you need a key pair, run `ssh-keygen` or similar on your admin computer to create one.
If you already have a key pair, use it.
Copy the public key to the server with `ssh-copy-id` or similar.
For example:

.install SSH key on server (🏠 admin computer)
[source%unbreakable#install-ssh-pubkey,text]
----
$ ssh-copy-id mario_server
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 2 key(s) remain to be installed -- if you are prompted now it is to install the new keys
mario2024@mario_server's password:

Number of key(s) added: 2

Now try logging into the machine, with:   "ssh 'mario_server'"
and check to make sure that only the key(s) you wanted were added.
----

Test that everything so far is working by running `ssh mario_server`.
You should see something like this:

.successful SSH to server (🏠 admin computer)
[source#successful-ssh-to-server,text]
----
$ ssh mario_server
Welcome to Ubuntu 24.04 LTS (GNU/Linux 6.8.0-31-generic x86_64)

... snip ...

Last login: Fri May  3 16:44:52 2024 from 192.168.1.225
user@server:~$
----

=== Provision server

Run `provision.sh` on your ((admin computer)) (_not_ on your server):

.mario first run (🏠 admin computer)
[source%unbreakable#mario-first-run,bash]
----
cd mario/ansible
./provision.sh
----

On this first invocation, mario will check for prerequisites and prompt you to enter values specific to your server into a configuration file.

.mario first run output (🏠 admin computer)
[source%unbreakable#mario-first-output,text]
----
You don't have a config file. I'll create one for you now.

Please edit 'config' and re-run this script.
----

Here's a guide for settings in your `config` that must be changed from their defaults.
Be sure to study the comments in that file, too.
I'll assume you have a domain name and a DNS provider with an API.
See <<Server domain name>> for details on how to obtain this.

`DNS_API_PROVIDER`::
Enter the name of your DNS provider here (the one with your DNS records).
mario configures Traefik to talk directly with your DNS server for issuing Let's Encrypt certs.
It doesn't need to know about your domain name registrar (the place you obtained your domain name), unless it is the same as your DNS provider.
`NAMECHEAP_*`, `DUCKDNS_*`, `R53_DNS_*`, `DO_*`...::
Enter credentials for only one provider, the same provider you specified in `DNS_API_PROVIDER`.
`DNS_RESOLVER_EMAIL`::
Enter an email matching what you use with your DNS API provider.
You may receive emails from Let's Encrypt at this address.
`MARIO_DOMAIN_NAME`::
This will be a name like `example.duckdns.org` or `example.com`.
Individual services will be named based on this, e.g. `jellyfin.example.com`.

Finish editing `config` and run `provision.sh` again.
This run will ask you for the password you set during <<OS-Installation>> and subsequent runs will not.
You should see output similar to this:

.mario second run output (🏠 admin computer)
[source#mario-second-run,text]
----
BECOME password:

PLAY [all] *********************************************************************

TASK [base : Configure apt cache] **********************************************
ok: [mario_server]

TASK [base : Install packages] *************************************************
changed: [mario_server]

... snip ...

PLAY RECAP *********************************************************************
mario_server               : ok=21   changed=0    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0
----

It takes around ten seconds for mine to complete.
All tasks will be `ok` in the recap for a fully provisioned system.
Some tasks will be `skipped` until Nextcloud is started for the first time--ignore those for now.

If `provision.sh` completed without errors, mario was able to get your server and services ready to use.
Proceed directly to <<Start services>>.

=== Server domain name

(((DNS)))
Your server needs a name.
You'll obtain a domain name from a registrar and input this hostname during <<OS-Installation>>.
I recommend using a single domain name and naming all your services with subdomains (e.g. `cloud.example.com`).
You can either use a free domain name or buy a domain name from a registrar.
mario needs the domain name to be able to use a DNS provider with an API for setting up HTTPS web traffic encryption.
Note that the registrar and DNS provider may differ.

You may also want to be able to refer to your server by name when you're away from your LAN if you allow WAN access and/or if you have a dynamic WAN IP address.
Check with your DNS provider about adding appropriate records for this purpose (e.g. `A` and `CNAME` records).

==== Public DNS

Duck DNS provides a free domain name and DNS service.
mario also works with paid services such as Namecheap, DigitalOcean, and Route 53.
I recommend any of the paid options over Duck DNS.
Support for other DNS providers (ahem, especially self-hosted ones!) may be added later.

NOTE: Public DNS records do not presume WAN access.
<<Digital security>> covers WAN access in detail.

===== Duck DNS

If you want a free domain name from a provider with an API, you can try your luck with Duck DNS.

. Start at https://duckdns.org.
. Log in and add a domain.

Your domain will be named something like `blah.duckdns.org`.
Use this in place of `example.com` as appropriate, e.g. use `cloud.blah.duckdns.org` for `cloud.example.com`.

===== Amazon Route 53

If you choose Route 53, create a new hosted zone with the domain name you own.
Make note of the Route 53 name servers.
Back at your registrar, input these name servers.

On Amazon IAM, create a user with permission to update this hosted zone.
Here's a policy with way too much access that nevertheless works:

.naive Route 53 policy
[source%unbreakable#naive-r53-policy,json]
----
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "route53:*",
      "Resource": "*"
    }
  ]
}
----

==== Dynamic DNS

If you want WAN access and your IP address changes periodically, it's handy to have this updated in DNS automatically.
Similar to Traefik setting up HTTPS certs, this uses a DNS provider API.
There are several options here, all left as exercises for the reader.
One idea is to find and stand up a dynamic DNS client for your Docker image.
These are generally very simple services to set up.
Another idea is to see if your router will do the dynamic DNS updates.

==== Internal DNS

It is handy to have an internal DNS server to be able to refer to your server by name.
These internal names should match the public names and point to ((LAN))-only private IP addresses.
This way you can use the same names inside and outside your LAN and your Let's Encrypt certs will work.
Your LAN router likely has a DNS server and may allow you to assign names to IP addresses.

If you don't have an internal DNS server, you can create more hostname to IP address mappings like the one we added in <<SSH setup>>.
Here's that hosts file again:

// this could also be one line with one IP and many hostnames

.hosts file with service names (🏠 admin computer)
[source%unbreakable#hosts-file-with-service-names,text]
----
# for provisioning from admin computer
192.168.1.100	mario_server

# for accessing services from admin computer
192.168.1.100	traefik.example.com
192.168.1.100	cloud.example.com
192.168.1.100	jellyfin.example.com
192.168.1.100	wallabag.example.com
192.168.1.100	scratch.example.com
----

Manually mapping IP addresses to hostnames with a hosts file is handy for initial setup and maintenance when your internal DNS server fails.
Remember that only the computer with these specific mappings will be able to use the names.
Test the mappings using `ping` on your admin computer.

TIP: I've shown examples of two styles of service domain names.
`cloud.example.com` indicates the function of the service, rather than the service's brand name.
`nextcloud.example.com` would work just as well.
The choice is yours.

=== Start services

mario has prepared your server to run a handful of services.
Docker and Docker Compose are installed.
Docker configuration files are stored in directories under `/root/ops`.
Data for services are stored in directories under `/data`.

None of the services are running yet.
We'll soon get to how to turn them on and start using them.

Let's first take a step to save a lot of typing.
Services are started and stopped with Docker Compose, which is always run with `docker compose`.
When you run `docker compose`, you must first be in a folder containing a `compose.yml` file.
By convention, the name of that folder is the name of the service.
A typical usage pattern is:

.start a service in its folder (🚀 server)
[source%unbreakable#start-service-in-folder,bash]
----
sudo su -
cd /root/ops/traefik
docker compose up -d
----

Try to avoid this method.
The fewer commands you run directly as `root`, the better.
I recommend this instead:

.start a service, explicit configuration file (🚀 server)
[source#start-service-explicit-config,bash]
----
sudo docker compose --file /root/ops/traefik/compose.yml up -d
----

mario installs a program called `dc` on the server to save you some typing:

.start a service with dc (🚀 server)
[source%unbreakable#start-service-with-dc,bash]
----
# equivalent to
# sudo docker compose --file /root/ops/traefik/compose.yml up -d
dc traefik up -d
----

TIP: sudo is required to run some commands, including `docker compose`.
The `dc` script will run `sudo` for you.

==== Start reverse proxy

(((Traefik)))
Stand up the ((reverse proxy)) first.
On your server, start Traefik with `dc traefik up -d`.
If that worked, wait a minute or two and visit `\https://traefik.example.com` in a web browser to see the Traefik dashboard.
While you are waiting for the dashboard, tail the logs with `dc traefik logs -f`.

It may take that minute or two for Traefik to set up Let's Encrypt HTTPS encryption certs, so don't worry if you get invalid cert warnings at first.
You should see something like this for a working Traefik service:

// These were some really long lines.
// I shortened the service name, removed dates and "INF" (info log level), and replaced https://acme-v02.api.letsencrypt.org/directory with an ellipsis.
// I also left out these lines:
//
// reverse-proxy-1  | 2024-05-04T10:03:01Z INF
// reverse-proxy-1  | Stats collection is disabled.
// reverse-proxy-1  | Help us improve Traefik by turning this feature on :)
// reverse-proxy-1  | More details on: https://doc.traefik.io/traefik/contributing/data-collection/
// reverse-proxy-1  |

.typical Traefik logs, edited for brevity (🚀 server)
[source#typical-traefik-logs,text]
----
+ sudo docker compose --file /root/ops/traefik/compose.yml logs -f
rp-1 | Traefik version 3.0.0 built on 2024-04-29T14:25:59Z version=3.0.0
rp-1 | Starting provider aggregator aggregator.ProviderAggregator
rp-1 | Starting provider *traefik.Provider
rp-1 | Starting provider *docker.Provider
rp-1 | Starting provider *acme.ChallengeTLSALPN
rp-1 | Starting provider *acme.Provider
rp-1 | Testing certificate renew... acmeCA=... providerName=myresolver.acme
^Ccanceled
----

If you waited a bit, re-loaded the page, and are still getting invalid cert warnings from your browser when you try to visit `\https://traefik.example.com`, read the Traefik log messages carefully and also see <<Encryption certificates>> for troubleshooting steps.
Once you're able to view the dashboard, stop tailing the Traefik logs with kbd:[Ctrl+c].

==== Start other services

Starting a mario service is always done with `dc SERVICE up -d`, just like we did with Traefik.
To stand up everything at once, you could use this shell script:

.start all services ad-hoc Bash script (🚀 server)
[source%unbreakable#start-other-services,bash]
----
for service in $(sudo ls /root/ops); do
    dc $service up -d
done
----

This will also pull and build images and update containers as necessary.
Services out of sync with their `compose.yml` file will be restarted.
This is idempotent: running and up-to-date services are left unchanged.

=== Encryption certificates

(((HTTPS)))
(((encryption, HTTPS)))
Traefik will automatically install ((Let's Encrypt)) ((cert))s to encrypt HTTP traffic.
The certs are issued using a https://doc.traefik.io/traefik/https/acme/#dnschallenge[DNS challenge].
This way to https://letsencrypt.org/docs/challenge-types/[authenticate a cert request] is especially handy for servers with zero public-facing inbound ports, allowing convenient HTTPS even within closed LANs.
The DNS challenge is configured using labels in Traefik's `compose.yml` configuration file.

(((SSL termination)))
Traefik can accept HTTPS, decrypt it, and pass along unencrypted HTTP to web services.
This is called SSL termination, and is configured by lines in Traefik's `compose.yml` mentioning `acme`.

Take a look at a `compose.yml` file for any service included with mario.
Every service has a `tls` section defined on its router to enable HTTPS encryption and SSL termination.

If you see cert warnings while trying to reach your web services, first examine Traefik logs as indicated in <<Start reverse proxy>>.
To increase the Traefik log verbosity, change `--log.level=INFO` to `--log.level=DEBUG` in Traefik's `compose.yml`, re-provision, and re-start Traefik.
To troubleshoot further, confirm DNS queries are succeeding since this affects the DNS challenge.

.example DNS tests
[source#example-dns-tests,bash]
----
####
# Try these commands on both the admin computer and server.
# Replace dig (and its arguments) with your favorite DNS tool.
# Replace traefik.example.com with your Traefik service name.
####

# Look up Traefik on default DNS server.
# Should quickly return a LAN private IP address.
dig traefik.example.com

# Look up Traefik server name on Quad9 DNS.
# - @9.9.9.9 forces Quad9's DNS service.
# - +short uses terse output
# Should return nothing--we didn't set an IP address.
dig @9.9.9.9 +short traefik.example.com

# Fetch TXT record for Traefik.
# Contains a long unique string while Traefik is executing a
# DNS challenge and is otherwise not set.
dig traefik.example.com TXT
----

=== Tiny test service

If you got this far, try standing up a test service.
This is useful to confirm networking is functional for Docker containers running on your host.
We likely already have this assurance if Traefik is working (since it requires networking for the DNS challenge), but this may still be a useful tool for another time, or at least a positive step towards creating your own useful services.

This service demonstrates pinging a public server.
On _your_ server, create the folder `~/ping/`.
Create a file `compose.yml` in that folder, containing:

.tiny test service config (🚀 server)
[source%unbreakable#tiny-test-service-config,yaml]
----
version: '3'

services:
  test:
    image: alpine
    command: ping example.com
----

In the folder `~/ping/`, run the command `sudo docker compose up`.
Hit kbd:[Ctrl+c] after a few seconds.
You should see something like this:

.start tiny test service (🚀 server)
[source%unbreakable#start-tiny-test-service,text]
-----
$ cd ~/ping/
$ sudo docker compose up
[+] Running 2/2
 ✔ Network ping_default   Created                                      0.1s
 ✔ Container ping-test-1  Created                                      0.1s

Attaching to ping-test-1
ping-test-1  | PING example.com (93.184.216.34): 56 data bytes
ping-test-1  | 64 bytes from 93.184.216.34: seq=0 ttl=55 time=3.477 ms
ping-test-1  | 64 bytes from 93.184.216.34: seq=1 ttl=55 time=3.236 ms
ping-test-1  | 64 bytes from 93.184.216.34: seq=2 ttl=55 time=3.363 ms
^CGracefully stopping... (press Ctrl+C again to force)
Aborting on container exit...
[+] Stopping 1/1
 ✔ Container ping-test-1  Stopped                                     10.4s
canceled
-----

[%unbreakable]
TIP: For extra credit, incorporate your tiny test service into mario.

This is the basis for adding more interesting services, too.
It's only a few more lines of code and configuration to create a small ((API)) or web service and a few more to publish it with your reverse proxy.

== Services

Now you can try out the services provisioned by mario.
This chapter covers what they provide and how to manage them.

[#purposes-of-default-mario-services]
.Purposes of default mario services
|===
|Purpose |See

|sync and share files, groupware |<<Nextcloud: Dateisynchronisation und -Freigabe>>
|stream music and home movies |<<Jellyfin: Audio- und Videostreaming>>
|read articles offline, without distractions |<<Wallabag: Artikel speichern und lesen>>
|keep other services up to date |<<Watchtower: service updater>>
|learn to code with visual tools |<<Scratch: visual programming>>
|===

These particular services are a small fraction of those available to self-host.
They reflect my users`' preferences (including and over-indexed to my own) in reading, sharing, media, and so on.
Getting them running will provide some useful functionality for your users and a good starting point for self-hosting whatever you want.

For each service you'll find my personal commentary and issues I encountered.
If I mention a feature I'd like to see added, I've also thought of adding it myself (or trying to convince someone else to add it, or raising money to pay someone to add it).
If I link to a bug that is closed in an issue tracker, it's because I have tested and, at the time of writing, I'm still experiencing the bug in an official/supported release that is supposed to have the fix.

Mobile usage is high for the users I support, so that was also a factor when I chose these services.
Nextcloud, Jellyfin, and Wallabag have mobile apps and integrations, and I use these often.

The server-side commands for managing services are standardized: You'll see the pattern `dc SERVICE ACTION ARGS` repeated many times.

// this forced page break was originally just to improve the print PDF layout, but I find it doesn't hurt the screen PDF layout so I don't use an ifdef::shb-printPDF[]

<<<

=== Nextcloud: Dateisynchronisation und -Freigabe

(((Nextcloud)))
A _Steadfast_ personal cloud needs convenient file sharing and synchronization.
Nextcloud is an excellent choice given its stability and popularity.
It can be daunting to self-host, but mario makes it easy and fun.

[#image-screenshot-nextcloud]
.Nextcloud Files app screenshot showing files, folders, and share buttons.
image::nextcloud.png[align="center",scaledwidth=80%]

A well-maintained Nextcloud server provides a solid foundation for de-Googling.
Nextcloud can be self-hosted for free when installed via mario.
Once you've got Nextcloud running, see <<More about Nextcloud>> for lots of my opinions on how best to customize it.

[#nextcloud_quick_start]
==== Quick start

. Provision with mario from your admin computer.
. Start Nextcloud with `dc nextcloud up -d` on your server.
. Navigate to `\https://cloud.example.com` on your admin computer.
. Follow the web-based setup page to create an admin account.
. Skip installing recommended apps.

==== Maintenance notes

Run `dc nextcloud pull && dc nextcloud up -d` on your server to upgrade and replace Nextcloud service containers.

==== Issues

See <<Various issues>>.

<<<

=== Jellyfin: Audio- und Videostreaming

(((Jellyfin)))
https://jellyfin.org[Jellyfin] is a personal streaming media server.
mario will set up a basic Jellyfin server.

[#image-screenshot-jellyfin]
.Jellyfin screenshot showing metadata for a movie. Big Buck Bunny is licensed CC BY-3.0 by the Blender Foundation.
image::jellyfin.png[align="center",scaledwidth=80%]

==== Quick start

. Provision with mario from your admin computer.
. Start Jellyfin with `dc jellyfin up -d` on your server.
. Navigate to `\https://jellyfin.example.com` on your admin computer.
. Follow web-based setup steps.

(((Jellyfin, using a GPU with)))
If you have a GPU, look into https://jellyfin.org/docs/general/administration/hardware-acceleration/[hardware acceleration].
This is useful if videos can't be played directly by a client and need to be transcoded on the fly.
Jellyfin can transcode using only CPU, but it is way faster with a GPU.

[%unbreakable]
TIP: Jellyfin can take advantage of some CPUs with built-in hardware transcoding.
Intel Quick Sync Video, for instance.

==== Maintenance notes

Run `dc jellyfin pull && dc jellyfin up -d` on your server to upgrade and replace the Jellyfin service container.

==== Issues

Here are some features I'd love to see implemented in Jellyfin.

===== Feature: Share playlists

https://github.com/jellyfin/jellyfin/issues/6264#issuecomment-1338518980[Playlists are private by design].
https://features.jellyfin.org/posts/173/share-playlists[I'd like the ability to share them].

===== Feature: Clips

I often want to share, hear, or re-watch a specific part of some media.
I think it would be just so cool to be able to https://features.jellyfin.org/posts/1036/bookmark-audio-video-segments[create clips] without actually creating new media files.

===== Feature: Offline mobile media

I want a Jellyfin mobile app that will automatically cache media and https://features.jellyfin.org/posts/218/support-offline-mode-on-android-mobile[allow playing while offline].

Workaround: there are two separate mobile apps that can download and cache media for offline playing.
https://github.com/jmshrv/finamp[Finamp] for music, and https://github.com/jarnedemeulemeester/findroid[Findroid] for video.

==== Manage Jellyfin media with Nextcloud

Jellyfin and Nextcloud both run on the same server.
You can use this fact to leverage their individual strengths as services while they operate on the same data, one as the media streamer and one as the media file manager.
mario creates special music and video folders on the server and makes them available to both services.
Nextcloud „external storages“ lets you upload files to these folders and Jellyfin will automatically notice and allow streaming the files you upload.

Nextcloud's `compose.yml` file has the entry `/data/shared/media/video:/data/video:rw` in `volumes`.
`/data/shared/media/video` is the path on the server that will hold the actual video files, `/data/video` is where they'll show up inside the container, and `rw` says Nextcloud has read and write access to this volume.
There's another similar folder for music files.
See <<Detailed setup>> for how to add them as external storages in Nextcloud.

In Jellyfin's `compose.yml` file you'll find similar lines to add music and videos volumes, but with `ro` (for read-only) instead of `rw`.
Jellyfin only needs read access to the folders to be able to stream the files they contain.

To see the Nextcloud-managed media files in Jellyfin, add two media libraries:

. Choose content type „Movies“, click the „+“ icon next to „Folders“, and choose `/data/video`.
. Choose content type „Music“, click the „+“ icon next to „Folders“, and choose `/data/music`.

<<<

=== Wallabag: Artikel speichern und lesen

(((Wallabag)))
https://wallabag.org[Wallabag] saves articles for distraction-free offline reading.

[#image-screenshot-wallabag]
.Wallabag screenshot showing unread articles view.
image::wallabag.png[align="center",scaledwidth=80%]

==== Quick start

. Provision with mario from your admin computer.
. Start Wallabag with `dc wallabag up -d` on your server.
. Navigate to `\https://wallabag.example.com` on your admin computer.
. Log in as `wallabag` user with password `wallabag`.
. Update password for `wallabag` user.

==== Maintenance notes

Run `dc wallabag pull && dc wallabag up -d` on your server to upgrade and replace Wallabag service containers.
If you run into any issues, try manually applying database upgrades (see <<Bug: Upgrades break everything>>).

==== Issues

Here's one issue I have with Wallabag and a feature I want.

===== Bug: Upgrades break everything

https://github.com/wallabag/wallabag/issues/6649[Database migrations are not (always?) automatically applied].
There may be other duplicate or related bug reports for this same thing, that's just one example.
Luckily, there's an https://github.com/wallabag/docker#upgrading[easy workaround].

Apply the workaround to a mario system with:

.force Wallabag database migration (🚀 server)
[source%unbreakable#force-wallabage-db-migration,bash]
----
dc wallabag exec app /var/www/wallabag/bin/console \
  doctrine:migrations:migrate --env=prod --no-interaction
----

The `exec` command says we want to run something in a container.
This runs the `console` utility in the `app` service container.
The second line indicates necessary database migrations (schema and data updates) should be run using `prod` settings, without interactive prompts.

This is idempotent, as database migrations should be.
After the first run, subsequent runs output: `[OK] Already at the latest version`.

It's unclear why thes migration is not automatically performed during an upgrade.
Perhaps it is only necessary in special cases--I've only had to do it twice in a few years.

===== Feature: Share with other users

I want to be able to https://github.com/wallabag/wallabag/issues/679[share content with other Wallabag users, within Wallabag].

<<<

=== Watchtower: service updater

((Watchtower)) is handy for keeping your Docker containers up to date.
It will discover and check outdated containers, pull new images, and restart services to create new containers.

// source: https://containrrr.dev/watchtower/images/logo-450px.png
// appears at: https://containrrr.dev/watchtower/
// license of the rest of watchtower is Apache 2.0
// This logo does not have license text.
// This logo image consists only of simple geometric shapes or text. It does not meet the threshold of originality needed for copyright protection, and is therefore in the public domain.
// See https://commons.wikimedia.org/wiki/Commons:Threshold_of_originality
// and https://en.wikipedia.org/wiki/Public_domain

image::watchtower.png[align="center",scaledwidth=40%]

If you never want containers upgrading automatically, don't run Watchtower.
Or, use https://containrrr.dev/watchtower/arguments/[configuration settings] to allow or block auto-upgrades for particular containers.
mario uses a container label to prevent watchtower from updating Scratch, for example.

==== Quick start

. Provision with mario from your admin computer.
. Start Watchtower with `dc watchtower up -d` on your server.

From now on it'll run in the background, automatically upgrading containers whenever possible, on a reasonable schedule (every 24 hours by default).
You can forget about it until it breaks (or breaks something else).

==== Maintenance notes

Run `dc watchtower pull && dc watchtower up -d` on your server to upgrade and replace the Watchtower service container.

==== Issues

It https://github.com/containrrr/watchtower/issues/90[does not automatically roll back if a container upgrade fails].
Granted, this would be challenging to implement.
A service might only have one-way database migrations, for example.
I think the Watchtower maintainers made the right decision to omit automatic rollbacks (likely to keep Watchtower simple).

You may experience an issue where a service is broken by Watchtower.
If you suspect this is the case and you know when the service started breaking, try to correlate that with any upgrades appearing in `dc watchtower logs`.
I avoid this by only using Watchtower for non-critical services.
I don't let Watchtower auto-upgrade my Nextcloud service, for example.

<<<

=== Scratch: visual programming

((Scratch)) is a popular and very approachable visual programming language geared towards interactive multimedia and learning.
The most well-known https://scratch.mit.edu[public online version] adds sharing, studios, comments, stars, hearts, endless memes and games.
These „social“ features may be exactly what a user wants/needs (e.g. one may remix an existing project and learn from it), or it may unintentionally reorient a user from productive creation to mindless consumption (e.g. doomscrolling).

This is where your new _Steadfast_ power comes in: Scratch can be self-hosted without the social features.
In fact, that's the simplest way to self-host it.
This is a great option if your users want to focus on creating in Scratch and being social in person. 😉

[#image-screenshot-scratch]
.Scratch screenshot showing a new empty project.
image::scratch.png[align="center",scaledwidth=80%]

Scratch doesn't require any persistent data, setup, nor auth.

==== Quick start

. Provision with mario from your admin computer.
. Start Scratch with `dc scratch up -d` on your server.
. Navigate to `\https://scratch.example.com` on your admin computer.

==== Maintenance notes

Scratch uses a custom Docker image so the upgrade process is significantly more complex than upgrading other services.
First, open the Scratch `custom/Dockerfile` on your admin computer.
That `Dockerfile` can be found in a subfolder of `mario/ansible` in the mario source code.

If you want to base the image on a newer version of Node.js, visit the https://hub.docker.com/_/node[Node.js page on Docker Hub] and select a version to use in the `FROM` line of the `Dockerfile`.
If you want to upgrade Scratch, visit the https://github.com/scratchfoundation/scratch-gui/releases[releases page] and select a version to use for `SCRATCH_VERSION` in the `Dockerfile`.

Re-run `provision.sh` on the admin computer.
Re-build the image with `dc scratch build --pull` on the server.
Finally, replace the Scratch service container by running `dc scratch up -d` on the server.

== What's next?

By this point, I'm assuming you've got your server running and some services too.
Here's where you can find a handful of ideas for what to try next.

=== Learn more

If you like this book, and you want to learn and do more, do it.
Ride that wave of inspiration.
Seek both breadth and depth.

For breadth, look for a comprehensive book about Linux since mario expects Linux, and a better understanding of Linux can help you customize your server with confidence.
There aren't any Ubuntu-specific dependencies, but Ubuntu is the only Linux flavor mario has been extensively tested on at the time of writing.
One of my first purchases when I wanted to just finally „get“ Linux was _UNIX: The Complete Reference_, a thousand-page monster covering many, many concepts.
I studied it in chunks, referred to it often, and never read it cover to cover.
If I started learning again from scratch today, I'd still have a book like that handy while studying online resources and trying stuff at home.

For depth, immerse yourself in fundamentals.
Learn how a computer works.
Push past abstractions and make progress towards first principles.
Take a computer science class in an area supporting something else you want to do.
For example, if you want to code your own web services, take a class in programming for the web.
If you want to understand how source code makes a computer do things, take a class in compilers.

Work through this book in a class or small group.
See <<Discussion topics>> and <<Exercises>>.

Participate in ((FOSS)) communities to learn from and share with others.
Pass on what you've learned.
File a bug.
Post in a forum.
It's fun!

(((SeaGL)))
Conferences like https://seagl.org[SeaGL] bring together bright minds on many topics, including self-hosting.
If you've done something cool, share it!

=== Use a GPU

(((GPU)))
A GPU offers more efficient video transcoding with Jellyfin, reducing server CPU usage and speeding up remote video streaming.

A FOSS voice assistant would benefit from a GPU.

A GPU could also speed up video transcoding and facial recognition.

Modern generative AI workloads like large language model chat and image generation are much faster with a GPU.

=== AI

(((AI)))
AI is once again the latest hotness.
You can run your own image generators and LLMs (large-language models) at home.
No GPU is required.
Here's a `compose.yml` that'll work with mario to stand up https://localai.io[LocalAI].

.example LocalAI service config
[source#example-localai-svc,yaml]
----
version: '3.6'

services:
  api:
    image: quay.io/go-skynet/local-ai:latest
    environment:
      MODELS_PATH: /models
    volumes:
      - /data/localai/models:/models:cached
    command: ["/usr/bin/local-ai" ]
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.localai-https.entrypoints=websecure"
      - "traefik.http.routers.localai-https.rule=Host(`localai.example.com`)"
      - "traefik.http.routers.localai-https.tls.certresolver=myresolver"
      - "traefik.http.routers.localai-https.middlewares=lan-only"
    networks:
      - traefik_default
    restart: unless-stopped
networks:
  traefik_default:
    external: true
----

Note the middleware to only allow traffic from your LAN.
This assumes your LAN uses 192.168.1.* addresses, and expects a corresponding label on the Traefik container to set up the ((middleware)), for example:

.label from Traefik configuration allowing only LAN access
[source#lan-only-traefik-conf-line,yaml]
----
"traefik.http.middlewares.lan-only.ipallowlist.sourcerange=192.168.1.0/24"
----

TIP: Use mario to provision your LocalAI service.

See the https://localai.io[LocalAI documentation] for further setup help.
Once you get that running, you can use the https://apps.nextcloud.com/apps/integration_openai[Nextcloud AI integration app] as a convenient frontend.

=== Pi-hole

(((Pi-hole)))
(((DNS)))
Running a https://pi-hole.net[Pi-hole] service in your LAN helps block advertisements, trackers, and bad actors using DNS block lists.

Clients (laptops, phones, etc) on your network use the Pi-hole as their DNS server, generally as part of DHCP (Dynamic Host Configuration Protocol) auto-configuration by your router or Pi-hole itself (if you use Pi-hole as your DHCP server).

The Pi-hole translates domain names to IP addresses.
If a domain name is on a block list, it returns a false IP address such as 0.0.0.0.

The technique is imperfect, yet simple and effective.

My Pi-hole server sits between my router's DNS server and all clients.

ifdef::backend-html5,backend-pdf[]
[#image-DNS-traffic-diagram]
.Pi-hole DNS traffic flow diagram.
image::DNS-traffic-diagram.svg[align="center",scaledwidth=80%]
endif::[]
ifdef::backend-epub3[]
[#image-DNS-traffic-diagram]
.Pi-hole DNS traffic flow diagram.
image::DNS-traffic-diagram.png[,571,651,align="center"]
endif::[]

Queries for domain names not on any block list will be answered directly or sent upstream.
I set up my Pi-hole to pass queries on to my home router, which will then query a DNS server outside my LAN as necessary.

It's easy to block individual domain names or entire lists as you see fit.
I've used this as an „impulse blocker“, helping the kids avoid distractions during remote school.

The Pi-Hole also has a list of local DNS entries.
I add a few domain names to this list for servers inside my LAN.

Note that some clients will by default bypass an auto-configured DNS server such as Pi-hole.
For example, https://support.mozilla.org/kb/firefox-dns-over-https[DNS over HTTPS in Firefox].

=== Single sign-on

(((Single sign-on)))
It would be convenient for users to be able to log in once to get access to all self-hosted services using a common, consistent, and well-designed mechanism (single sign-on), and for sysadmins to be able to manage all users and groups in one place (centralized identity management).

https://goauthentik.io[Authentik] is one service providing this, and appears to have all the features I want (single sign-on, backend user database, integrates with everything I self-host).
I want to try it out and see it running well for a good while before adding it to mario.
Some of the other self-hosting solutions mentioned in <<Alternativen zu mario>> do include FOSS central identity management.

=== Enforce SSH public key auth

Some sysadmins choose to require public key authentication for ((SSH)) logins.
I think https://security.stackexchange.com/q/3887[it's a good idea] but I didn't want to force it on you so I didn't include it in mario.
I'm using this as an opportunity to demonstrate how to extend mario.
Add this Ansible task to `roles/base/tasks/main.yml`:

.enforce SSH public key auth (🏠 admin computer)
[source#enforce-ssh-pubkey-auth,yaml]
----
# This does not affect logging in from a console (e.g. directly connected
# keyboard and monitor, or a virtual console).
- name: Disable tunneled clear text passwords
  copy:
    src: pka-only.conf
    dest: /etc/ssh/sshd_config.d/
    owner: root
    group: root
    mode: 0400
  notify:
    - restart sshd
----

Add this to `roles/base/handlers/main.yml`:

.Ansible handler to restart SSH (🏠 admin computer)
[source%unbreakable#ansible-ssh-restarter,yaml]
----
- name: restart sshd
  service:
    name: sshd.service
    state: restarted
----

Create `roles/base/files/pka-only.conf` with:

.SSH server config lines (🏠 admin computer)
[source%unbreakable#ssh-server-config,text]
----
PasswordAuthentication no
AuthenticationMethods publickey
----

Finally, re-run `provision.sh`.
From now on, your server will require public key authentication for SSH logins.

=== Allow WAN access

mario blocks ((WAN access)) by default.
Read <<Digital security>> to decide if you want this or not.
You may remove this protection by removing the `lan-only` ((middleware)) from the corresponding router's Traefik label.
For example, to allow WAN access to Nextcloud, make this change in Nextcloud's `compose.yml`:

.patch for WAN access to Nextcloud (🏠 admin computer)
[source%unbreakable#open-wan-access,diff]
----
- traefik.http.routers.nc-https.middlewares=nc-head,nc-redir,lan-only
+ traefik.http.routers.nc-https.middlewares=nc-head,nc-redir
----

Similarly for Jellyfin, you may delete the whole line referencing the `lan-only` ((middleware)) in Jellyfin's `compose.yml` if you decide to expose that service on your WAN.

=== More about Nextcloud

Nextcloud is a key part of my self-hosting setup.
I wanted to include a lot of additional details without cluttering up <<Services>>, so you'll find these extra sections here.

==== Basic install

(((Nextcloud, installing)))
A basic (default, un-customized) Nextcloud install provides remote file storage, organization, and sharing.
It keeps track of actual files and folders stored somewhere (local, remote, cloud, wherever) and tracks additional metadata about those files and folders in a database.
You access it via a web browser and there is a desktop client to sync files locally, similar to Dropbox, Google Drive, and OneDrive.

I've come to _really_ trust file sync with the Nextcloud desktop app.
If I see a check mark on my desktop app, I know everything is properly synchronized with the server.
I am constantly creating and editing content locally and counting on sync to work (usually on my desktop computer), or creating and editing directly in Nextcloud via the web UI.

There are also apps for mobile devices.
I'll come back to mobile later in the following sections.

==== Object storage

Nextcloud is able to use ((object storage)) for primary data storage.
This is an advanced topic left as an exercise to the reader.
I'll assume primary storage on a local HDD set up by mario.

==== Security

(((Nextcloud, security and)))
A basic Nextcloud install appears to have excellent security.
The source is in heavy use and is backed by a solid company with a reputation that depends on their commitment to security.
They make it easy to lock down and vet (it is FOSS after all).
The defaults appear secure.
They follow best practices.
They have a public bounty program and threat model.

==== Detailed setup

To confirm reproducibility of your Nextcloud server, destroy and re-create it (before you use it for real).
After you get it working once, stop it with `dc nextcloud down`.
Destroy all persistent data with `sudo rm -rf /data/nextcloud`.
That _really_ deletes everything.
Re-provision with mario (run `provision.sh` again).
Follow the setup steps again, see <<nextcloud_quick_start>>.

Read the official docs at `/settings/help` or https://docs.nextcloud.com.

Add apps at `/settings/apps`.
See <<Customization>> for tips on how to roll out apps thoughtfully and which ones are worth your time.

Test configuring a mail server and sending an email at `/settings/admin` (Basic settings).

Add users at `/settings/users`.

Check logs for all containers related to Netcloud with `dc nextcloud logs -f`.

Check Nextcloud internal logs at `/settings/admin/logging` in the web UI or `/data/nextcloud/root/data/nextcloud.log` on the server.
These include specific Nextcloud internal server messages and are often more useful to me than the container logs.
If you see a warning about „1 error in the logs since DATE“ (or perhaps a couple) at `/settings/admin/logging`, you can probably ignore it.
These initial logged errors appear to be harmless, possibly a result of some install-time race conditions.
It is still a good idea to review all logged errors.

Review „Security & setup warnings“ at `/settings/admin/overview`.
You can ignore the warning ‟Could not check for JavaScript support. Please check manually if your webserver serves `.mjs` files using the JavaScript MIME type.” if this succeeds on your admin computer:

.JavaScript fetch test (🏠 admin computer)
[source%unbreakable#js-fetch-admin,bash]
----
curl -I https://cloud.example.com/apps/settings/js/esm-test.mjs
----

The warning is because the Nextcloud `app` container https://github.com/nextcloud/server/issues/42989[fails at a test] to request a JavaScript test file, likely because of a DNS issue.
To fix it, the request must be able to work from within the Nextcloud `app` container.
In other words, this must succeed (return a successful HTTP response code and include the header `content-type: text/javascript`):

.JavaScript fetch test (🚀 server)
[source%unbreakable#js-fetch-server,bash]
----
dc nextcloud exec app \
  curl -I https://cloud.example.com/apps/settings/js/esm-test.mjs
----

Some maintenance requires the `occ` tool (short for „ownCloud command“).
Run it with `dc nextcloud exec --user www-data app php occ`.

Add `/data/video` as an External storage.
Media files uploaded there will automatically appear in Jellyfin.
First, visit `/settings/apps/featured` and install the „External storage support“ app.
Next, visit `/settings/admin/externalstorages` and install the „External storage support“ app.

* Folder name: Video
* External storage: Local
* Authentication: None
* Configuration: `/data/video`
* Set users, previews, sharing, and remaining options as desired.

Add `/data/music` as an External storage, similar to `/data/video`.

==== More maintenance tips

Visit `/settings/admin/overview` periodically to check for system and security issues that may require manual intervention.
Perform any recommended maintenance on that page.
Ignore the Update section, it may disagree with Docker Hub.
Visit `/settings/admin/logging` periodically to review all server-side log messages.

Running `dc nextcloud pull && dc nextcloud up -d` (on the server) will pull the most recent image of https://github.com/nextcloud/docker with the `stable` release tag.
Using this tag will likely be stable enough for you and your users.
`stable` generally corresponds to the version they call _previous_ at https://docs.nextcloud.com/.

You may opt to „pin“ your Nextcloud to a more specific tag such as `27.1.5-apache`.
This gives you the chance to review and test each upgrade.
You can pin a release tag in Nextcloud's `compose.yml` where the image name appears, just trade `stable` for the tag you choose.
All available tags are https://hub.docker.com/_/nextcloud[listed at Docker Hub].

NOTE: Nextcloud's blog posts and marketing materials use different version names than the release versions from source control.
„Hub 6“ on the blog refers to versions `27.\_._` in source control, „Hub 7“ to `28.\_._`, and so on.

===== Release cadence

(((Nextcloud, release cadence of)))
https://docs.nextcloud.com/server/stable/admin_manual/release_schedule.html[A major release is shipped every four months].
The Nextcloud apps I care about seem to keep up with this pace, but it does feel a bit aggressive to me.
Developers need to modify their apps each time at least slightly, or heavily if breaking API changes occur.
Thankfully the Nextcloud team https://help.nextcloud.com/t/new-process-for-documenting-core-code-changes-that-affect-app-developers/149828/1[carefully documents changes] to ease app maintenance for developers.

As a _Steadfast_ sysadmin, be sure to check your `/settings/admin/overview` page before upgrading Nextcloud to make sure all the apps you use will work with the version you're upgrading to.
You can override an out-of-date app with the „enable untested app“ option under `/settings/apps`.
Sometimes this works.

Since four months seemed to me like a short window for major releases I started a https://help.nextcloud.com/t/major-release-cadence/161685[thread about it].
Review their https://github.com/nextcloud/server/wiki/Maintenance-and-Release-Schedule[Maintenance and Release Schedule] to make sure your current version is still supported.

==== Performance

If you use mario to deploy Nextcloud, you'll start with a nominally performant server suitable for a small handful of users, assuming you have sufficient hardware resources.
mario includes an author-approved selection of the https://docs.nextcloud.com/server/stable/admin_manual/installation/server_tuning.html[recommended server tuning steps].

I've only had one performance issue in the years I've hosted Nextcloud (knock wood!), so I'll mention it here.
I was seeing slow web requests along with https://github.com/nextcloud/server/issues/35311[lots of database activity].
This had me under the hood with MariaDB for a while.
They've since https://github.com/nextcloud/server/pull/33540[fixed the root cause] so it isn't a problem for new installations.

==== Customization

(((Nextcloud, apps for)))
Nextcloud can be used as-is (see <<Basic install>>) or heavily customized.
The simplest and safest way to customize is by installing an app from the built-in app store (`/settings/apps`), especially if an app is marked „featured“.
These _Nextcloud apps_ are installed on the server, expanding the functionality of a base Nextcloud instance.

Here are some Nextcloud apps I've tried, what they do, and a ruling on whether they're worth looking into.
Read „Worth your time?“ as „Adam maybe tried this app and has shared his opinion whether others will find this particular app worth the effort to learn and maintain, based on his own experiences projected onto our possibly different use cases.“
Grain of salt, in other words.
When in doubt, start small (default Nextcloud install), and roll these out thoughtfully if you do at all.

[cols="1,1,2",id=nextcloud-apps-commentary]
.Nextcloud apps commentary
|===
|Nextcloud App |Purpose |Worth your time?

|Antivirus for files |virus scan uploads |*Yes*. Note: https://github.com/nextcloud/files_antivirus/issues/219[uploads from desktop clients are not scanned for viruses].
|Analytics |track and graph metrics |*Yes*. Only for small/simple use cases though.
|Appointments |easy 3rd party scheduling |*Yes*. Requires careful calendar curation. Somewhat fiddly setup.
|Calendar |manage meetings and appointments |*Yes*. See also: <<Spurious event updated notifications>>.
|Circles |arbitrarily group users |*No opinion*. I don't have enough users to justify this.
|Collectives |wiki or knowledge base |*Maybe*. Looks like a useful way to organize a set of related documents. Requires Circles.
|Cookbook |recipe manager |*Yes*. Great at importing from web pages (thanks to standardized recipe data already present in HTML source). I wish it were better at printing/exporting though.
|Contacts |address book |*Yes*.
|Dashboard |landing page |*No*. I like to go right to my files.
|Deck |kanban board |*No opinion*. I tried it a little and it worked, I just don't use kanban much.
|Draw.io |diagram editor |*Yes*.
|Duplicate Finder |find and cull duplicate files |*No*. Slow and opaque. I recommend https://github.com/pauldreik/rdfind[rdfind] instead.
|Electronic Signatures |e-sign documents |*No*. Requires a 3rd party service. I'd rather have drawn signatures. See <<Draw signature in forms>>.
|End-to-End Encryption |encrypt files server-side, decrypt with client |*No*. Unnervingly buggy. Confusing UI/UX. See <<End-to-End Encryption>>.
|Files |file management, sharing |*Yes*, although the „Versions“ tab is not very useful.
|Forms |Google Forms alternative |*Yes*.
|Full text search |search through all documents |*Maybe*. Fast. Buggy. Likely dormant project. See <<Full text search>>.
|Holiday Calendars |easily add public holiday calendars |*Yes*. The configuration for this app shows up under „Personal“ -> „Availability“ for me, not „Groupware“ (although the URL path is `/settings/user/groupware`).
|Maps |maps and directions |*Yes*. Grab a cup of tea if you have lots of photos with GPS coordinate metadata.
|Mail |email |*No opinion*. I tried it briefly and it choked on my bazillion Gmail messages. And yes, I do want to de-Gmail someday.
|Memories |photos |*Yes*. Requires Photos.
|News |track blogs and news via rss/atom feeds |*Yes*.
|Nextcloud Office |edit spreadsheets, slides, etc. |*Yes*. I don't love this but I need it. Maybe that's a „No“? Mobile apps for this are painful. See <<Nextcloud Office>>.
|Notes |simple markdown-based note taking |*Yes*. There's an excellent companion mobile app. Replaced Google Notes for me.
|Passwords |password manager |*No*. Dormant.
|PhoneTrack |location sharing and tracking |*Yes*. UI is feature-rich and complicated. Traveled movement lines are cool.
|Photos |photos, sorta |*No*. Slow, clumsy, lacking features compared with other FOSS photo management software. Use Memories instead. Note that Memories depends on the Photos app.
|Polls |simple polls |*Yes*.
|Ransomware protection |warns for bad file names on upload |*No*. Too many false positives. Unmaintained.
|Recognize |face recognition |*No*.
|Suspicious login |warn about suspicious IPs |*No*. Too many false positives.
|Tasks |tasks/todos |*Yes*.
|Tables |tabular data entry and API |*No*. Not yet, although keep an eye on this as a potentially powerful and useful ((low-code)) platform.
|Talk |video and text chat |*No*. Works, just not as well as other video and text chat services/apps. I do use it for my chicken safety system and I see it improving a lot with each release. For now I recommend https://signal.org[Signal] instead.
|Temporary files lock |avoid edit conflicts |*Yes*.
|Text |edit text documents |*Yes*. I'm a huge fan of Markdown plain text documents, and Nextcloud handles these well. It has a nice web-based collaborative editor. I like pasting in rich text and letting the editor auto-convert it to Markdown. See also: <<Mobile text editing is hard>> and <<Spurious web text editor conflicts>>.
|Video converter |transcode videos |*No*. Cool idea but the project appears dormant.
|===

==== Full text search

(((Nextcloud, full text search and)))
This app allows you to search through all content of all documents on your server.
The search syntax is hard to get right.
It https://github.com/nextcloud/fulltextsearch/issues/601[uses a lot of CPU] and is memory-hungry too.

The GitHub project repositories are pretty quiet. See:

* https://github.com/nextcloud/fulltextsearch/pulse
* https://github.com/nextcloud/files_fulltextsearch/pulse
* https://github.com/nextcloud/fulltextsearch_elasticsearch/pulse

==== Mobile

(((Nextcloud, mobile and)))
Nextcloud works OK as the backend for a mobile device.
It can be your single reliable source of truth for contacts, calendars, tasks, and most everything else that matters on mobile.
You can open files and edit them, but the UI/UX is bad.
See <<Mobile text editing is hard>> for a couple workarounds.

Besides the primary mobile app (called simply „Nextcloud“), there are other mobile apps made to work with Nextcloud apps.
Here are the ones I recommend.
I don't have an iPhone so these are only Android apps.

[cols="1,1,2",id=recommended-nextcloud-mobile-apps]
.Recommended Nextcloud mobile apps
|===
|Mobile app |Works with Nextcloud apps |More info

|DAVx5 |Calendar, Contacts, Tasks |https://davx5.com
|Maps Geofavorites |Maps |https://github.com/penguin86/nextcloud-maps-client
|NC Passwords |Passwords |https://gitlab.com/joleaf/nc-passwords-app
|Nextcloud Cookbook |Cookbook |https://github.com/nextcloud/cookbook
|Notes |Files, Notes, Text |https://github.com/nextcloud/notes-android
|OpenTasks |Tasks |https://github.com/dmfs/opentasks
|Nextcloud Talk |Talk |https://apps.nextcloud.com/apps/spreed
|===

Android devices usually ship with ((groupware)) (calendar and contacts) apps, or you can install your favorite ones.
DAVx5 handles synchronization of groupware data to and from your device.
DAVx5 is only necessary on Android, perhaps because iOS has better native WebDAV support.
DAVx5 is not needed on Murena phones (/e/ OS).

There are actually two Cookbook apps.
Either works fine for me.
I'm not picky, I just need to see the ingredients and directions.
Looks like the one by „Teifun2“ is more popular.

Maps Geofavorites lets you easily save arbitrary GPS coordinates to the Maps Nextcloud app.
Handy for remembering where you parked your bike, for example.

Notes looks best configured in Grid View.

Talk... despite my own advice, I find myself using Talk anyway.
I like having my own chat server, I guess.
I am listing it here because I do actually use it, and to complain that https://github.com/nextcloud/talk-android/issues/217[I can't read messages offline].
It is also under heavy development and improving lots with every release.

These are just a few examples.
Since you've got all your data and Nextcloud always uses open formats, you can ride the wave of improvements and enjoy what works best.
For example, I just started using https://github.com/jonasoreland/runnerup[RunnerUp].
When I save my tracks in Nextcloud, they automatically show up in Maps.
Nice!

==== Nextcloud vs. ownCloud

(((Nextcloud, ownCloud vs.)))
At first glance it's a bit difficult to tell the difference between Nextcloud and ((ownCloud)).
This follows since Nextcloud started as a fork of ownCloud.

So why should you choose one over the other?
A healthy FOSS project is generally also an active project, so one way to guide your decision is by comparing activity metrics on GitHub.
See https://github.com/owncloud/core/pulse[owncloud/core activity] and https://github.com/nextcloud/server/pulse[nextcloud/server activity].
Based on those two sets of metrics it appears Nextcloud is thriving and ownCloud is dying.

Another interpretation is that ownCloud has a smaller and slower-moving core codebase.
More work is necessary to make a truly rigorous comparison.

See also: <<traits-of-good-services>> and <<traits-of-bad-services>> in <<Choose services>>.

==== Nextcloud Office

(((Nextcloud, office and)))
https://nextcloud.com/office/ gives some strong hints how the company behind Nextcloud wants us to think of „office“ and their plans for it as a suite of related tools.
They clearly intend a holistic, integrated office experience, and Nextcloud can be configured to be used in this manner.
https://nextcloud.com/office/ covers editing office documents (rich text and spreadsheets) collaboratively, along with uses for the Notes, Collectives, and Tables apps.
It provides some clever and useful workflow ideas.

Given that wide a scope, ((groupware)) should be part of „office“ too, so instead let's for now focus specifically on collaborative editing of office documents.
Doing this within Nextcloud requires an https://apps.nextcloud.com/apps/richdocuments[app called Nextcloud Office] as well as a separate backend service, either ((Collabora)) or ((ONLYOFFICE)).
My strong preference is for Collabora, in line with <<Good for self-hosting>>; despite fewer stars on GitHub, it appears Collabora development is flourishing while ONLYOFFICE is stagnant (although it's hard to tell which of the many ONLYOFFICE repositories on GitHub are relevant here).

==== Various issues

Here's a selection of my favorite bugs and feature requests for Nextcloud.

===== Spinner on mobile

When you first open the Nextcloud mobile app, a loading spinner shows up in front of a cached view of whatever files and folders existed the last time you use the app.
If you ignore it and tap to navigate your way into a folder or open a file, you may end up tapping a different one than you intended because the folder order can change _as you are tapping the screen_.

Workarounds:

* wait until the spinner completes (usually takes me about one second)
* reduce chance of reordering with „A - Z“ or „Z - A“ sorting instead of „Newest first“ or „Oldest first“

===== Mobile text editing is hard

(((Nextcloud, mobile and)))
Nextcloud makes it easy to get to your stuff via mobile devices, but editing is a pain.

This is not a Nextcloud-only problem; I find _all_ mobile text entry and editing cumbersome.
This applies to email, plain text, Markdown, and office documents.

In Nextcloud-land, one workaround to improve plain and Markdown text entry is to use the https://github.com/nextcloud/notes-android[Notes app on Android] or https://github.com/nextcloud/notes-ios[iOS].
It has separate editing and viewing modes and more aggressive synchronization.
With Notes you have a better chance of up-to-date data and fewer conflicts.

Another workaround is to use https://github.com/gsantner/markor[Markor].
Install that app, then:

. In the Nextcloud mobile app, „Download“ or „Sync“ the file you wish to view or edit locally.
This caches a copy on your phone.
. In the Nextcloud mobile app, choose „open with“ for the file.
Should open instantly.
. If you make changes to the file, save it, then manually „Sync“ the file in the Nextcloud app.
It appears local changes like these never make it to the server otherwise.

See https://jenson.org/text/ for background on why mobile text editing is a complex and multifaceted problem.

===== Cumbersome mobile setup

To sync calendars, tasks, and contacts with your phone's storage of same on Android, you must install and configure the 3rd party DAVx5 app.
https://help.nextcloud.com/t/what-does-android-file-sync-do-for-a-nextcloud-account/154330[I don't know why DAVx5 is required], but https://murena.com[Murena] figured it out for me.
Their Android-derived /e/ OS includes native support for Nextcloud accounts, removing the requirement for DAVx5.
Users with iOS and other OSes besides Android can sync groupware-related data https://docs.nextcloud.com/server/stable/user_manual/en/groupware/[without DAVx5].

===== Spurious web text editor conflicts

Collaborating on plain text and Markdown text files sometimes results in spurious conflicts.
Editing is interrupted before it starts, and the web-based text file editor shows you two versions of the file side by side.
The left side is labeled „Use current version“, and the right says „Use the saved version“ (or equivalents for your locale or specific client).

Apparently the browser has a saved copy in local storage or something that gets loaded first and considers it the „current“ version.
Then it loads the one on the right and calls it the „saved“ version, and if they differ you get to choose.

Workaround: pick the one on the right.
That's the latest and greatest copy as it exists server-side.

Why the... never mind, just pick the one on the right.
If you're curious and want to dig in deeper, follow these links:

* https://github.com/nextcloud/text/issues/2388[Shared text file is not up-to-date with saved file]
* https://github.com/nextcloud/text/issues/4078[Changing File from Desktop leads to conflict in browser, even if browser was not doing any changes]
* https://help.nextcloud.com/t/text-document-current-vs-saved-version/151600[Text: document current vs. saved version] (by yours truly)

Related desktop client bug: https://github.com/nextcloud/desktop/issues/2467[Nextcloud-Client creating conflicts when it should not].
Conflicts seem to appear in cases where there shouldn't be any.
Workarounds: wait 10 seconds or so between saves until the desktop client syncs and returns to idle (roll your eyes while you wait).
Also, check out the https://apps.nextcloud.com/apps/files_lock[Temporary files lock] app for semi-automated advisory locking (e.g. quickly communicate „gimme a minute, I'm editing that Markdown text file“).

===== Draw signature in forms

Forms are handy for gathering simple minimally-structured data... surveys, RSVPs, stuff like that.
The data are just dumped into a spreadsheet.
With a signature field Forms could be used to add a drawn signature to a form like a contract or waiver.

There are extant Nextcloud online signature apps that incorporate https://en.wikipedia.org/wiki/Digital_signature[digital signatures].
I don't want or need digital signatures, especially since they appear to rely on 3rd party services.
I really just want a low-tech image that looks like a drawn signature at the bottom of a page.
It doesn't even need to be wet ink.
If you want that too, vote for or help with https://github.com/nextcloud/forms/issues/947.

https://github.com/OpenSignLabs/OpenSign[OpenSign] and https://github.com/docusealco/docuseal[DocuSeal] are two alternative FOSS self-hostable apps supporting drawn signatures.

===== Release script missing from source

Nextcloud is FOSS, although https://help.nextcloud.com/t/build-bzip-and-package-from-git/58341[some release scripts are held back].
They may or may not be required to release those, I don't know.
I hope they do decide to release them, for the same reasons the rest of Nextcloud is FOSS.

===== Spurious event updated notifications

The Calendar app is quite useful and perhaps the most heavily used by me and my users.
I have grown to expect one particular erroneous „event updated“ notifications, possibly caused by calendar client/sync issues.

On one shared calendar (with many clients) I often get notifications that so-and-so „updated event XYZ in calendar ABC“, but the only actual thing that occurred is that one of the clients just sync'd (or perhaps made some innocuous change to an event) and https://github.com/nextcloud/calendar/issues/5879[Nextcloud thinks it was a meaningful update].
At least, I think that's what's happening... some changes (like changing the event's date) do show up with the old and new values made explicit.
As an aside, I do like this „explicit diff“ behavior showing the exact changes made to an event's Title, Time, Location, or Description.

==== End-to-End Encryption

End-to-End encrypted folders seems like a great idea.
There's a Nextcloud app for this and I recommend you avoid it.

It seems close to working, but it feels like early-release software.
The UI/UX is confusing, and I ran into a dealbreaker bug that left files decrypted server-side.
Furthermore, https://help.nextcloud.com/t/how-to-setup-e2e-encryption-for-shared-folders/165610[sharing] https://help.nextcloud.com/t/e2ee-and-file-sharing/145547[doesn't] https://github.com/nextcloud/end_to_end_encryption/issues/520[work], https://github.com/nextcloud/end_to_end_encryption/issues/82[there's no web client], https://github.com/nextcloud/end_to_end_encryption/issues/285[the roadmap is unclear], and https://github.com/nextcloud/end_to_end_encryption/issues/8[keys are always stored on the server] (these are thankfully stored encrypted).

ifdef::backend-pdf[]
Sorry for all those really long links.
Whew!
Deep breaths, self, deep breaths.
Count to ten.
endif::[]

Proceed carefully with the End-to-End Encryption Nextcloud app.
Review https://github.com/nextcloud/end_to_end_encryption/issues[known issues], make sure you can live with all those, then test it out thoroughly using a throwaway/sandbox Nextcloud instance.
Make sure it works with all clients you plan to use it with (e.g. desktop, mobile).

==== AIO installer

(((Nextcloud, installing)))
Among the myriad Nextcloud install methods, there's a relatively new and interesting AIO („all-in-one“) installer (https://nextcloud.com/all-in-one).
It's free for an instance with less than 100 users.
The AIO takes a different approach than mario, it configures and manages multiple Nextcloud-related service containers for you.
I recommend the mario method instead for its flexible and empowering experience of learning how to add and manage individual containers yourself.

See the https://github.com/nextcloud/all-in-one[AIO readme] for more information.

== Weitere Ressourcen

Visit https://selfhostbook.com for all supporting material including source code for this book and mario.

* https://selfhostbook.com/code/[Source code]
* https://selfhostbook.com/contact/[Contact information]

Patches and feedback are most welcome.
This book is just a part of something big and I'm glad you're a part of it too!

=== Support

Here are a few ideas for when you get stuck.

* Ask for help in forums and chats related to a product/project.
* If you're confident you've found a bug, file an issue with the product/project.
* Ask https://selfhostbook.com/chat/[other readers] for help.
* Try your luck in semi-moderated public places.
Don't expect much from these, although you may get lucky from time to time.
** https://reddit.com/r/selfhosted/[selfhosted subreddit]
** https://reddit.com/r/homelab/[homelab subreddit]
** https://matrix.to/#/#Nextcloud:matrix.org[Nextcloud chat]
** https://matrix.to/#/#selfhosted:matrix.org[self-hosted chat]
* Hire me to help you out.

=== Alternativen zu mario

If you're in a hurry, you can find one-click-install appliances with many ready-to-go apps.
(((FreedomBox)))
https://freedombox.org[FreedomBox] is one promising contender in this space.

There are also many shortcuts and frontends for self-hosting.
For example, https://openmediavault.org[openmediavault] looks like a cool way to build a ((DIY)) (do it yourself) ((NAS)) (network attached storage).

(((YunoHost)))
(((CasaOS)))
(((Runtipi)))
And there are countless more of these kinds of partial or full-service self-hosting solutions, such as:

https://yunohost.org[YunoHost]::
  Not considered, I prefer always using containers.
https://casaos.io[CasaOS]::
  New, interesting, very little documentation.
https://runtipi.io[Runtipi]::
  New, interesting, uses ((Docker Compose)) and Traefik.

These look intriguing, and it's hopeful (and overwhelming) to see many options in this space.
I evaluated these only just enough to get the sense they didn't fit my wants and needs.
I'm a crotchety old man and I'm reluctant to change, but I still do, sometimes.
If and when I adopt something new, it must pass a high bar, ideally most or all these tests:

.Checklist: Self-Hosting Solution Viability
[#solution-viability-checklist]
****
* [ ] Will it work for years with minimal tinkering?
* [ ] Is it easily extensible?
* [ ] Do I trust the maintainers?
* [ ] Does it employ technologies I'm familiar with?
* [ ] Does it weaken or strengthen security by changing my ((attack surface))?
* [ ] Does it add features/value I need/want, beyond what I'm already able to do?
* [ ] Will it help my users?
* [ ] Will it help me learn what I need/want to learn, and safely take care of the rest for me without my needing to learn more?
* [ ] Will it help me figure out why I made a change to one of my services two years ago?
* [ ] Does it phone home, using telemetry or my data in a way I don't approve?
* [ ] Does it hold back „enterprise“ features I need, even for my scaled-down use case?
Is it annoying about this, reminding me often?
* [ ] If I want paid support, is it available?
* [ ] Is it popular?
Has it been around a while, and do I expect it to endure?
****

See also: <<traits-of-good-services>> and <<traits-of-bad-services>> in <<Choose services>>.

After brief reviews, I find existing self-hosting solutions generally:

* are new and immature
* lack proper documentation
* do too much: try to solve many problems without sufficient inertia/resources to maintain it all
* don't do enough: just another Linux distro with an added layer to discover and install apps
* make opinionated tech choices I don't agree with
* have a limited list of apps in their app stores and exclude the ones I want
* have too many apps in their app store, without good ways to compare quality, privacy, features
* are GUI (graphical user interface)-focused where I prefer working on a command line

Still, check `'em out.
They might work better for you if you don't need the level of power and control provided by this book.
By the time I publish, they (or some new contenders) might grow to overcome my approach.
Please let me know what you discover.
If I missed something, I'd love to learn about it!

(((Ansible)))
(((Clace)))
(((Cosmos Cloud)))
(((DockSTARTer)))
(((HomelabOS)))
(((Start9)))
(((MicroCloud)))
(((LibreServer)))
(((LinuxServer.io)))
(((NextcloudPi)))
(((UBOS)))
Here are some more related and interesting self-hosting solutions worth researching further:

* https://github.com/davestephens/ansible-nas[Ansible NAS]
* https://clace.io[Clace]
* https://cosmos-cloud.io[Cosmos Cloud]
* https://dockstarter.com[DockSTARTer]
* https://homelabos.com[HomelabOS]
* https://start9.com[Start9]
* https://canonical.com/microcloud[MicroCloud]
* https://libreserver.org[LibreServer]
* https://www.linuxserver.io[LinuxServer.io]
* https://nextcloudpi.com[NextcloudPi]
* https://ubos.net[UBOS]

== Discussion topics

Here are some conversation starters for a class or small group.

. What services do _you_ run?
Why?
For whom?
. What are some considerations when choosing between public cloud and on-premise self-hosting?
. Compare and contrast different options for bare metal self-hosting hardware in terms of setup cost, power usage, and expandability.
. Why does the author encrypt all network traffic, even in a closed LAN?
. Review this book for poor security practices.
How might it be improved?
. Why is privacy important, especially with digital information?
. What's the best part about self-hosting?
. What are some pitfalls of self-hosting?
. What is the future of self-hosting?
. What is the ideal number of users to support with a single self-hosted server?
. Is the _Steadfast_ method useful for larger groups, big families, church congregations, schools, businesses, and governements?
Why or why not?
. How might this book be adapted for:
.. intermittent power
.. intermittent network
.. local-only network
.. clustered hardware
. Consider FOSS with respect to human attention and focus.
Contrast with non-FOSS.
. What approaches in this book may be conceptually dangerous or misleading?
Why?
How could they be improved?
. Summarize this book in one sentence.
. How might you detect if your server has been compromised?

== Exercises

Exercises for individual practice and study groups.

. Stand up a service besides those included with mario using an existing image.
For example, a https://awesome-selfhosted.net/tags/personal-dashboards.html[dashboard].
. Build a custom image.
Hint: use `docker build` or https://buildah.io[Buildah].
. Run a container using your custom image.
. Create a service (using your container) to know if it is time to reboot your server.
Hint: check if `/host/var/run/reboot-required` exists.
. Stand up a second Nextcloud service for experiments.
Use it to test out the latest release or a custom app.
. Try Nextcloud with object storage for primary storage.
. Adapt this guide to a Linux distribution besides Ubuntu.
. Help resolve a bug mentioned in this book.
. Set up periodic automatic offsite backups.
. Add a GPU to your server.
. Enable GPU transcoding in Jellyfin.
. Sign the open letter at https://publiccode.eu[Public Money, Public Code] because software paid for with taxes should be FOSS.
. Aggregate logs.
. Pick a Docker container that doesn't need to be able to initiate outbound network connections.
Prevent it from doing so and prove to yourself it works.
. What if the server won't boot?
.. Describe troubleshooting steps, in detail.
.. Make a plan for system recovery when it fails to boot.
. Set up https://en.wikipedia.org/wiki/Single_sign-on[single sign-on].
. Set up https://fail2ban.org[Fail2Ban].
Feed it logs from various services.
. Set up https://suricata.io[Suricata] network analysis and threat detection.
. Try running containers with https://podman.io[podman].
. Read up on other ways to isolate processes, e.g. FreeBSD jails and chroot.
. Contribute to mario.
. Move secrets used by mario into an Ansible vault or a self-hosted service intended for managing secrets.
. Adapt mario to use podman.
. Adapt mario to use https://kubernetes.io[Kubernetes].
. If you have a dynamic WAN IP address, create or use an existing dynamic DNS update client container.
. Stand up a mail relay container such as https://github.com/crazy-max/docker-msmtpd or https://github.com/namshi/docker-smtp.
Allow all mario-managed services to send email through this relay.
. Stand up your own DNS server.
. Reorganize mario services into distinct Ansible roles.
Upload the roles to https://galaxy.ansible.com[Ansible Galaxy] as a playbook bundle.
. Traefik's Docker integration has https://doc.traefik.io/traefik/providers/docker/#docker-api-access[security implications].
Test these risks against your security considerations following <<Threat model>>.
If you should mitigate this risk based on your threat model, harden mario so even if Traefik were compromised it would not compromise the whole server.
Review the Traefik docs on this topic and https://github.com/wollomatic/traefik-hardened[traefik-hardened] to get some ideas.
. Modify mario to https://docs.docker.com/engine/security/userns-remap/[always run containers as unprivileged (non-root) users].
. Use appropriate ownership and permissions for persistent container data.
. Set up https://github.com/strukturag/nextcloud-spreed-signaling#running-with-docker[Nextcloud Talk high-performance backend].
. https://docs.docker.com/network/packet-filtering-firewalls/#docker-and-ufw[Uncomplicated Firewall and Docker do not get along well].
Work around this and share your solution with others.
. Try https://nixos.org[Nix and NixOS].
. Roll your own Linux distro.
. Build, configure and deploy an https://opnsense.org[OPNsense firewall].
. Set up your own https://headscale.net[headscale] VPN/tailnet for remote LAN access.
. Improve preview/thumbnail generation in Nextcloud.
.. Research first: Will you and your users benefit from the change?
Are there security implications?
How does default preview generation work?
What file types are supported by the default previewer and other previewers?
How much disk space is used?
How fast is it, subjectively and objectively?
What maintenance will it require once enabled?
.. Create a test bed with a clean install and many preview-able files of various file formats.
Find or write code for recording objective performance metrics (e.g. time it takes to generate previews for a folder containing many files of various types).
Consider both client- and server-side performance.
Keep manual testing notes (subjective measurements).
.. Compare https://apps.nextcloud.com/apps/previewgenerator[Preview Generator], https://github.com/h2non/imaginary[Imaginary], and any other extant previewers.
.. Establish baseline performance metrics before making any changes.
.. Enable one or the other, get timings, repeat for each previewer.
.. Evaluate the change.
Is it noticeable?
Does your timing script show any difference?
How much disk space is used for previews?
How challenging was this to enable?

The detailed steps in the last exercise suggest what may be required in general to achieve better outcomes.
I've omitted them from the other exercises for brevity.
Please apply similar detailed steps elsewhere as desired.

:sectnums!:

== Afterword

In the words of Scott McNealy, former CEO of Sun Microsystems:

____
Open source is free like a puppy is free.
____

Everybody loves a puppy, right?
_Right??_
I sure hope so.
Because--fair warning--if you spend too much time with your „puppy“ (self-hosting, FOSS, etc.), your partner will show up with an actual puppy.

[#image-puppy]
.Open Source is free like a puppy. Pictured: actual puppy.
image::puppy.jpg[align="center",scaledwidth=80%]

If your problem is _that_ cute, I suppose it's not too a bad problem to have.
I hope you find what you need to keep _your_ puppies happy!

Finally, I'd like to share an Ursula K. Le Guin quote.
According to her:

____
A book is just a box of words until a reader opens it.
____

Dear Reader, _this book exists because you exist_.
I hope it serves you well.
I am humbled and grateful for your support.
Thank you, thank you, thank you.

== Danksagungen

Sometimes I feel more like a birthday boy than an author, accepting gifts from so many generous people.
I truly couldn't have done this alone and I am so, so grateful for you.

Thanks to Eva for more than I could ever account for here, from „What if it rains?“ to leading by learning and fearlessly doing.
For supporting my dreams, including this book: your several inspiring rounds of thoughtful code review, technical critique, developmental editing, copy editing, proof reading, and line editing.

Thanks to my daughter for your fantastic illustrations.

Thanks to Deb Nicholson for writing the meaningful Foreword.

Thanks to my family and friends for tolerating my protracted FOSS self-hosting boondoggles, including this book.

Thanks to _Pro Git 2_, my inspiration to switch to Asciidoctor.

Thanks to the contributors to the myriad FOSS programs I used to create this book, especially John MacFarlane and the Pandoc team, Dan Allen and the Asciidoctor team, and Bram Moolenaar and the Vim team (rest in peace, Bram).

Thanks to Rob Smith and all #underlug for help with hardware, networking, Ansible, and Traefik.

Thanks to the „Deadbeat Dads“ Bryan Daisley and Rob Floberg for your invaluable feedback.

// alphabetical by last name

Thanks to all my beloved beta testers, including Andrew Davidson, Brendan Kidwell, Eva Monsen, Don O'Neill, and Lenny Wondra.

Thanks to Bob Nystrom for your mind-expanding design review.

Thanks to Lenny Wondra for your deeply effective tech review and editing.

Thanks most of all to my wife and kids for supporting and believing in me.
For all the cooking, talking, listening, art, coding, math, music, and love.
Aren't we lucky?!

== Glossary

Here's a list of definitions for some of the more non-obvious terms I use in this book to clarify how I use them.
These stick to common use as much as possible.
Specialists in computer science, security, administration, networking and so on will have more nuanced definitions.

// source for "These days that pretty much means git" statement: https://en.wikipedia.org/wiki/Git#Adoption

((AI))::
  Artificial intelligence.
((API))::
  Application programming interface. Provides a way to interact with a service from software. Useful for writing apps and integrations.
((attack surface))::
  Total of possible attack vectors. Fewer is more secure. Example: closing all but the ports you need open reduces yours.
((backend))::
  I use this term to refer to either a service (e.g. a database) or server. It's something you more frequently interact with indirectly, say, via a frontend like a web app or mobile UI.
((bare metal))::
  Physical nearby computing resources, as opposed to rented compute time on someone else's hardware. Used in this book primarily to indicate hardware autonomy.
((block storage))::
  Cloud storage option with direct filesystem access including files and folders. Used directly/natively/locally from an OS. Size is relatively fixed and determined at creation time.
((bot))::
  Short for robot. Software performing autonomous tasks such as responding to chat requests or attacking vulnerable servers.
((cattle vs. pets))::
  Highlights two distinct sysadmin approaches to systems/services. Cattle are automated, ephemeral, and hopefully immutable. Pets are managed manually, stateful, and long-lived.
((cert))::
  Shorthand for HTTPS encryption certificate.
((change management))::
  The means and methods of transitioning a group of people from one set of tools and processes to another.
((cloud))::
  An ambiguous amount of remote hardware. Scalable, programmable, and networked. „The cloud“ or „public cloud“ is someone else's hardware while „personal cloud“ is your own.
((cluster))::
  Collated collection of machines treated as a single machine to achieve higher scale computing power.
((compute))::
  Noun: CPU or GPU resources expended when running software services.
((container))::
  Running instance of an image. Containers may also be referred to as „guests“, although this is more commonly used to describe VMs.
((CPU))::
  Central processing unit. The main brain of the computer; the place where most of the math happens.
((data))::
  Noun, plural. Yes, I use the annoying plural form! Sorry, old habit.
((data sovereignty))::
  Full control of your data. For example, having original copies of your files.
((deploy))::
  Prepare a service for use. Typically involves building or copying files before a service is started.
((dogfooding))::
  Being a user of something you also created and/or maintain. „Eat your own dogfood.“
((DHCP))::
  Dynamic Host Configuration Protocol. This is one way computers get IP addresses and related networking settings.
((DIY))::
  Do it yourself. Said of activities involving some amount of learning and tinkering you'd otherwise pay for. Cooking, for example. Also: self-hosting.
((DNS))::
  Domain Name System. Maps domain names to IP addresses.
((domain name))::
  How a server, service, or group of services are identified, e.g. `example.com`.
((DRM))::
  Digital restrictions management. Ancient, evil technology designed to prevent unapproved consumption of content. Probably used for surveillance too.
((egress))::
  Any outbound data transfer or download, in public cloud terms.
((entrypoint))::
  How traffic enters the Traefik reverse proxy; network ports.
((firewall))::
  Means of controlling network traffic between computers.
((fork))::
  Verb: to split one software project into two. Noun: a derivative software work. The fork diverges from the original (otherwise it would simply be a copy). One or many software projects may succeed the original. Forking software is a useful and common activity.
((FOSS))::
  Free and open-source software. An acronym designed to unite the goals of the FSF and the OSI.
((FSF))::
  Free Software Foundation. They strongly defend the „F“ in FOSS.
((frontend))::
  The UI for a system or service.
((full-disk encryption))::
  When an entire storage area is cryptographically protected.
((GB))::
  Gigabyte. Typically 1,000^3^ (1,000,000,000) bytes for HDDs, or 1,024^3^ (1,073,741,824) bytes for RAM, for historical reasons. Cloud storage providers use the second (powers of two) form.
((good, fast, and cheap))::
  Used with a wink in this text because https://en.wikipedia.org/wiki/Project_management_triangle[typically we must pick two].
((Good Thing))::
  A hand-wavy way of saying something is self-evidently wonderful.
((groupware))::
  Software for group collaboration. Loosely: mail, calendar, and contacts. Sometimes includes collborative editing of office documents and spreadsheets.
((GPU))::
  Graphics processing unit. Originally intended for graphics. Found to be useful for many specialized compute workloads including transcoding video.
((GUI))::
  Graphical user interface.
((HDD))::
  Hard disk drive. Stores ones and zeros on spinning metal platters.
((homelab))::
  A physical or conceptional space for do-it-yourself flexible systems administration leaning and experimentation. A homelab is not quite what this book describes, it is more of an at-home hardware, software, and electronics maker-space. A _Steadfast_ server (or „personal cloud“) should be nearly always online and useful--at least the user-facing part. Some self-hosters call this environment „homeprod“. Far from this level of hair-splitting detail, I'll use „homelab“ as a shortcut for „self-hosting setup“ and/or „homeprod“.
((host))::
  The computer where Docker containers run. Also called a „server“ in this text.
((hostname))::
  Name for a single server/computer/device.
((HVAC))::
  Heating, ventilation, and air conditioning.
((idempotent))::
  An operation which enacts changes only until an end state is reached. Repeating the operation has no effect once the end state is reached. For example, updating an OS. After the OS is up to date, updating again will cause no changes to the list of installed packages (assuming no new updates become available while updating).
((image))::
  A filesystem with code and dependencies necessary to run a container.
((immutable))::
  Doesn't change. For example, a particular Docker image. A container instantiated from that image can be modified, but the image cannot; a new image must be built.
((IPMI))::
  Intelligent Platform Management Interface. Used for remote server management including reboots and OS installs.
((IPS))::
  Intrusion prevention system. Mitigates the risk of penetration.
((isolation))::
  For software services: Keep separate from others. Eases sysadmin tasks such as preventing dependency version conflicts.
((ISP))::
  Internet service provider.
((kernel))::
  The part of the OS that talks directly with hardware.
((LAN))::
  Local area network. For example, the network used by computers and devices to talk with each other inside your home.
((LFNW))::
  LinuxFest Northwest. Annual conference in Bellingham, Washington dedicated to serving and connecting open source communities. Established in 2000.
((Linux))::
  The most popular server OS. Also works fine on a desktop or laptop. The old me would have insisted on calling it „GNU/Linux“ or „a Linux distribution“. A lot has happened since then, and I've come to believe „Linux“ is enough to describe the OS used for self-hosting in the context of this book.
((low-code))::
  High-level application development platform with reduced focus on traditional programming. Typically provides a GUI and requires less files with configuration and code. Useful for prototyping or replacing some simpler data entry and analysis applications.
((LTS))::
  Long-term support. A stable software release, supported for many years.
((mario))::
  Provisioning system included with this book to assist with learning how to set up and maintain your own server. Consists of scripts, documentation, and configuration files.
((NAS))::
  Network-attached storage. A server made for storing data. Usually has several HDD bays in a non-rackmount box-like form factor. Likely has less CPU and RAM (and less power usage) than what I describe in <<Server>>.
((NIC))::
  Network interface card, also called a network adapter. Hardware for receiving and sending data over a network.
((object storage))::
  Relatively unlimited and typically remote cloud storage option. Actual data are abstracted: backups and structured access require special services, indexes, and software.
((OCR))::
  Optical character recognition. The process of converting images of text to actual text.
((OOB))::
  Out-of-band (management). A means of remote low-level server control including power cycling and console interaction, typically provided by an independently powered and networked embedded computer. See also: IPMI.
(((operating system)))
OS::
  Operating system.
((OSI))::
  Open Source Initiative. More concerned with the „OSS“ of FOSS.
((PHP))::
  PHP: Hypertext Processor. Programming language built for the web.
((PoE))::
  Power over ethernet. Utilizes an ethernet cable for electricity as well as data.
((port))::
  Along with an IP address, a number used to connect to a service. Reserved port numbers such as 80 for HTTP are listed in `/etc/services`.
((partition))::
  Delineated section of a HDD or block storage, formatted with a filesystem such as ext4 or ZFS.
((port forward))::
  Router configuration to send traffic for a particular port to a computer inside a LAN.
((process))::
  Instance of running software. Note that „running“ processes are described in more detail by a lower-level state such as running, sleeping, idle, waiting for I/O completion and--my personal favorite--zombie.
((provision))::
  As in, „provision a server“. Set up a machine or otherwise bring it into alignment with a known/good configuration.
((RAID))::
  Redundant array of inexpensive disks. Allows flexible use of multiple drives for redundancy and/or speed, as desired.
((registrar))::
  Domain name vendor. May also offer other name- and hosting-related services.
((reproducible))::
  Able to be repeated following specific steps. E.g. „repro“ a bug or „a reproducible [software] build“. If two people try to repro a bug, they should have the same experience. If two people each build an image from the same `Dockerfile`, they should produce the same image. In practice, bug repros and build products are close enough and never exactly the same.
((reverse proxy))::
  Networking software for filtering and directing traffic. In a self-hosted context, useful for SSL termination and for running several self-hosted web services with different domain names with a single IP address.
((router))::
  Network device used to handle traffic at the boundary between networks such as a WAN and LAN. A SOHO router typically also provides various other functions including DNS, DHCP, switching, firewalling, and Wi-Fi. See: port forward. A Traefik router is something different: this is a software logic connecting entrypoints to services. See <<Traefik architecture>>.
((runtime))::
  The period of time when a software is running; when a set of machine instructions becomes a running process. Also used to describe a set of tools/libraries to facilitate same. May appear as „runtime environment“ in the latter form.
((SeaGL))::
  Seattle GNU/Linux Conference. Held yearly since 2013.
((server))::
  A computer that generally stays powered on and uses networking for interaction instead of a monitor, keyboard, or mouse. Also called a „host“.
((service))::
  A long-running process used by other local and remote processes to do something useful.
((SOHO))::
  Small office / home office.
((source control))::
  A system for tracking changes in source code along with who made the change, why, and when. Git is one such system.
((source of truth))::
  The authoritative (home for a) document, perhaps among some number of available choices/copies.
((SSD))::
  Solid-state drive. A hard drive that doesn't spin.
((SSH))::
  Secure Shell. Provides encrypted remote command line access to a server.
((SSL termination))::
  Accepting encrypted traffic and passing along unencrypted traffic. Act performed by Traefik reverse proxy in a mario-provisioned server. More accurately and less often referred to as „TLS termination“. Actual SSL is deprecated.
((sysadmin))::
  Portmanteau of „systems administrator“. A party responsible for the upkeep of a computer system.
((threat model))::
  Analysis of risks and defenses of digital assets.
((TB))::
  Terabyte. Like GB, can be either base-10 or base-2, so: 1,000^4^ (1,000,000,000,000) bytes for HDDs and 1,024^4^ (1,099,511,627,776) bytes for RAM.
((TLD))::
  Top-level domain. For „example.com“, „.com“ is the TLD.
((UI))::
  User interface. The means of interaction between a user and a system, e.g.: a web site or mobile app. Often considered along with user experience and notated „UI/UX“.
((UPS))::
  Uninterruptible power supply. A battery that sits between your server and an outlet, often with extra features such as a power outage alarm or surge suppressor.
((UX))::
  User experience. The nature of interaction between a user and a system they are using. Includes ease of use and steps involved to complete a task. Often considered along with user interface and written as „UI/UX“.
((volume))::
  Docker facility to mount a folder on the server to a folder inside a container. This is a common means of persisting container data that would otherwise be ephemeral.
((VM))::
  Virtual machine. OS isolation technique simulating nearly all aspects of hardware including power, input, and output.
((VPN))::
  Virtual private network. Useful to „teleport home“ and behave (from a networking perspective) as if you are inside your home LAN.
((WAN))::
  Wide-area network. Everything outside your LAN / home network / router.
((ZFS))::
  A filesystem with many advanced features such as encryption, bit rot mitigation, journaling, volume management, and snapshotting. Used to stand for Zettabyte File System.

// Ideally I'd like a full set of these lists for every output.
// See am64 in ../Readme.adoc
//
// The ifndef block disables all cross references for print PDF output. See:
// * https://github.com/Alwinator/asciidoctor-lists/issues/14
// * https://discuss.asciidoctor.org/asciidoctor-pdf-cross-ref-to-a-page-number-td8418.html
//
// An EPUB backend quirk necessitates explicit IDs for everything. See:
// * https://github.com/Alwinator/asciidoctor-lists/issues/25

ifndef::shb-printPdf[]
== Cross references

Here are lists of links to significant blocks of titled content.

=== Figures

list-of::image[]

=== Tables

list-of::table[]

=== Sidebars

list-of::sidebar[]

=== Code snippets

list-of::listing[]

endif::[]

// only matters for PDF output
// see https://docs.asciidoctor.org/asciidoc/latest/sections/user-index/
ifdef::backend-pdf[]
[index]
== Index
endif::[]
